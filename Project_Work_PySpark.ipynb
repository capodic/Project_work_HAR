{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project Work PySpark.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eO5gmmsLyNaP",
        "dd2Tdmtk9oPm",
        "EQtSH-qAyA7u",
        "ApHdx9T7si5C",
        "Rp0cc3PWvvrY",
        "HEXab2uBt5V9"
      ],
      "mount_file_id": "1hukTMjPfH4gN2Mh19DEf--Rd2JrAf52U",
      "authorship_tag": "ABX9TyNpRym7CSvmIiyeAFlO+8iB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/capodic/Project_work_HAR/blob/dev/Project_Work_PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSS43fmw3f3F"
      },
      "source": [
        "#<center><font size=6 color=\"blue\">**Sviluppo modello di Machine Learning per classificazione Attività Umane (HAR Human Activity Recognition) con Spark ML e predizione e raggruppamento dei risultati con strutture dati distribuite e modello di programmazione Map/Reduce**</font></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNauPxIP6A3I"
      },
      "source": [
        "## <font size=5 color=\"blue\">**Descrizione del progetto**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APlu9rDE44Ez"
      },
      "source": [
        "Si vuole realizzare la classificazione di attività motorie umane (HAR) a partire da collezioni di dati da sensori inerziali (IMU) 9 assi (3 assi per accelerometro, magnetomero e giroscopio) realizzando un modello di machine learning com ML lib di Apache Spark e programmando una pipeline di calcolo Map/Reduce in grado di effettuare la predizione di massive quantità di dati (molte sorgenti di dati che emettono con continuità nel tempo)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Le6DKAk6G7L"
      },
      "source": [
        "#<font size=5 color=\"blue\">**Fase 1 : Sviluppo modello di Machine Learning con Apache Spark ML lib**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ibxuv5h9welv"
      },
      "source": [
        "## <font color=\"red\">✪</font> Installazione PySpark "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIm6qK_trirk",
        "outputId": "60dc4416-0d83-4a5e-efdb-586116dccf40"
      },
      "source": [
        "!pip install pyspark\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/db/e18cfd78e408de957821ec5ca56de1250645b05f8523d169803d8df35a64/pyspark-3.1.2.tar.gz (212.4MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4MB 66kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 15.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=30b8f6cdc80b95c3aac41cdf8e03ff2529866fc49cb531e1770a8b1ebd194a39\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/1b/2c/30f43be2627857ab80062bef1527c0128f7b4070b6b2d02139\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OswE9Ybwpa4"
      },
      "source": [
        "## <font color=\"red\">✪</font> Inizializzazione SparkSession e App (include lo SparkContext come attributo..)\n",
        ">Viene allocata memoria diversa del default per problemi di esaurimento durante il training dei modelli di ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JBcybf8s3aH",
        "outputId": "3285b8a4-5a5d-47a9-b736-792fc1d012a3"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "# spark = SparkSession.builder.master(\"local[*]\").getOrCreate() # errore heap esaurito in cvModel, occorre incrementare le risorse pre memory.offHeap.size\n",
        "spark = SparkSession.builder.master(\"local[*]\").config(\"spark.executor.memory\", \"70g\").config(\"spark.driver.memory\", \"50g\")\\\n",
        "                                    .config(\"spark.memory.offHeap.enabled\",True).config(\"spark.memory.offHeap.size\",\"8g\").appName(\"Project Work\").getOrCreate()\n",
        "# spark = SparkSession.builder.master('local[*]').config(\"spark.driver.memory\", \"50g\").appName('Project Work').getOrCreate()  #versione breve, dovrebbe andare anche solo incrementando driver.memory\n",
        "print(\"SparkSession creata...\",spark)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SparkSession creata... <pyspark.sql.session.SparkSession object at 0x7f0574b40750>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq4-FvYcF6GK"
      },
      "source": [
        "Print the Current Spark Context Settings/Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqgD-PDcFg0c",
        "outputId": "44b0445a-252b-46de-e7b5-8d3b0fdb7cca"
      },
      "source": [
        "configurations = spark.sparkContext.getConf().getAll()\n",
        "for conf in configurations:\n",
        "    print(conf)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('spark.driver.memory', '50g')\n",
            "('spark.driver.host', '1877f2b01123')\n",
            "('spark.memory.offHeap.size', '8g')\n",
            "('spark.driver.port', '36397')\n",
            "('spark.app.id', 'local-1626287149264')\n",
            "('spark.app.startTime', '1626287147546')\n",
            "('spark.executor.id', 'driver')\n",
            "('spark.executor.memory', '70g')\n",
            "('spark.sql.warehouse.dir', 'file:/content/spark-warehouse')\n",
            "('spark.rdd.compress', 'True')\n",
            "('spark.serializer.objectStreamReset', '100')\n",
            "('spark.master', 'local[*]')\n",
            "('spark.submit.pyFiles', '')\n",
            "('spark.submit.deployMode', 'client')\n",
            "('spark.memory.offHeap.enabled', 'True')\n",
            "('spark.app.name', 'Project Work')\n",
            "('spark.ui.showConsoleProgress', 'true')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrXXwybsJbLG"
      },
      "source": [
        "## <font color=\"red\">✪</font> Importazione librerie \n",
        "> **Pandas** per la gestione dei dataframe  \n",
        "> **Numpy** per la gestione efficente di array e funzioni relative  \n",
        "> **Matplotlib** per la visualizzazione di grafici (libreria a basso livello)  \n",
        ">  **Seaborn** per la visualizzazione di grafici (libreria ad alto livello che si apploggia a Matplotlib)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3r5hY6QMAXO",
        "outputId": "a18d7a9c-bbc1-491d-ad43-37368c5e5f92"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "print('lib caricate')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lib caricate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nggcQbIIKMZv"
      },
      "source": [
        "## <font color=\"red\">✪</font> Caricamento dati da GitHub\n",
        "> Vengono importate tutte le colonne relative a ora, timestamp (epoch), accelerazioni lungo gli assi x, y, z e viene aggiunta la colonna delle **label** non contenuta originariamente nei dati  \n",
        "> NB: le righe sono già ordinate temporalmente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "fGSLqtp0S4uf",
        "outputId": "4e29cf19-5dc4-4453-b59f-777526eb8d11"
      },
      "source": [
        "#definizione di valori per le label delle attività che si deducono dal nome del file di dati e non dati dati stessi \n",
        "SEDUTO=0; INPIEDI=1; SDRAIATO=2; CAMMINA=3; SCENDE=4; SALE=5;\n",
        "#pathdir_read = '/content/drive/MyDrive/Colab Notebooks/data/'\n",
        "\n",
        "pathdir_read ='https://raw.githubusercontent.com/capodic/Project_work_HAR/main/dataset/'  #github path\n",
        "df_labels = [SEDUTO, INPIEDI, SDRAIATO, CAMMINA, SCENDE, SALE]\n",
        "\n",
        "# prendo colonne di interesse, con header sulla prima riga (0)\n",
        "sed = pd.read_csv(pathdir_read+\"seduto-Accelerometer.csv\", header = 0)#, usecols=[3,4,5])  \n",
        "sed ['label']= SEDUTO\n",
        "\n",
        "inp = pd.read_csv(pathdir_read+\"inpiedi-Accelerometer.csv\", header = 0)#, usecols=[3,4,5])\n",
        "inp ['label']= INPIEDI \n",
        "\n",
        "sdr = pd.read_csv(pathdir_read+\"sdraiato-Accelerometer.csv\", header = 0)#, usecols=[3,4,5])\n",
        "sdr ['label']= SDRAIATO \n",
        "\n",
        "cam = pd.read_csv(pathdir_read+\"cammina-Accelerometer.csv\", header = 0)#, usecols=[3,4,5])\n",
        "cam ['label']= CAMMINA \n",
        "\n",
        "sce = pd.read_csv(pathdir_read+\"scende-Accelerometer.csv\", header = 0)#, usecols=[3,4,5])\n",
        "sce ['label']= SCENDE \n",
        "\n",
        "sal = pd.read_csv(pathdir_read+\"sali-Accelerometer.csv\", header = 0)#, usecols=[3,4,5])\n",
        "sal ['label']= SALE \n",
        "\n",
        "print(\"Dati dei singoli file CSV caricati\")\n",
        "\n",
        "# definizioni var da usare nel lavoro\n",
        "\n",
        "#lista dei singoli df\n",
        "df_list = [sed, inp, sdr, cam, sce, sal]\n",
        "# df che contiene tutti i dati\n",
        "df = pd.concat([sed, inp, sdr,cam,sce,sal], ignore_index=True)\n",
        "# df che contiene le solo colonne delle features\n",
        "df_features = df.iloc[:,:-1]\n",
        "#ds che contiene la serie delle label\n",
        "ds_labels = df.iloc[:,-1]\n",
        "label_txt = ['Seduto','In Piedi','Sdraito','Cammina','Scende','Sale'] # label_text[SEDUTO] => restituisce 'Seduto'\n",
        "\n",
        "df\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dati dei singoli file CSV caricati\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch (ms)</th>\n",
              "      <th>time (01:00)</th>\n",
              "      <th>elapsed (s)</th>\n",
              "      <th>x-axis (g)</th>\n",
              "      <th>y-axis (g)</th>\n",
              "      <th>z-axis (g)</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1590567416332</td>\n",
              "      <td>2020-05-27T10:16:56.332</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.818</td>\n",
              "      <td>-0.156</td>\n",
              "      <td>0.572</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1590567416337</td>\n",
              "      <td>2020-05-27T10:16:56.337</td>\n",
              "      <td>0.005</td>\n",
              "      <td>-0.826</td>\n",
              "      <td>-0.158</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1590567416342</td>\n",
              "      <td>2020-05-27T10:16:56.342</td>\n",
              "      <td>0.010</td>\n",
              "      <td>-0.824</td>\n",
              "      <td>-0.159</td>\n",
              "      <td>0.576</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1590567416347</td>\n",
              "      <td>2020-05-27T10:16:56.347</td>\n",
              "      <td>0.015</td>\n",
              "      <td>-0.825</td>\n",
              "      <td>-0.160</td>\n",
              "      <td>0.570</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1590567416352</td>\n",
              "      <td>2020-05-27T10:16:56.352</td>\n",
              "      <td>0.020</td>\n",
              "      <td>-0.823</td>\n",
              "      <td>-0.157</td>\n",
              "      <td>0.573</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88075</th>\n",
              "      <td>1590568227882</td>\n",
              "      <td>2020-05-27T10:30:27.882</td>\n",
              "      <td>96.840</td>\n",
              "      <td>-0.885</td>\n",
              "      <td>-0.169</td>\n",
              "      <td>0.417</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88076</th>\n",
              "      <td>1590568227887</td>\n",
              "      <td>2020-05-27T10:30:27.887</td>\n",
              "      <td>96.845</td>\n",
              "      <td>-0.893</td>\n",
              "      <td>-0.178</td>\n",
              "      <td>0.412</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88077</th>\n",
              "      <td>1590568227892</td>\n",
              "      <td>2020-05-27T10:30:27.892</td>\n",
              "      <td>96.850</td>\n",
              "      <td>-0.899</td>\n",
              "      <td>-0.179</td>\n",
              "      <td>0.405</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88078</th>\n",
              "      <td>1590568227897</td>\n",
              "      <td>2020-05-27T10:30:27.897</td>\n",
              "      <td>96.855</td>\n",
              "      <td>-0.898</td>\n",
              "      <td>-0.173</td>\n",
              "      <td>0.396</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88079</th>\n",
              "      <td>1590568227902</td>\n",
              "      <td>2020-05-27T10:30:27.902</td>\n",
              "      <td>96.860</td>\n",
              "      <td>-0.899</td>\n",
              "      <td>-0.171</td>\n",
              "      <td>0.389</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88080 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          epoch (ms)             time (01:00)  ...  z-axis (g)  label\n",
              "0      1590567416332  2020-05-27T10:16:56.332  ...       0.572      0\n",
              "1      1590567416337  2020-05-27T10:16:56.337  ...       0.577      0\n",
              "2      1590567416342  2020-05-27T10:16:56.342  ...       0.576      0\n",
              "3      1590567416347  2020-05-27T10:16:56.347  ...       0.570      0\n",
              "4      1590567416352  2020-05-27T10:16:56.352  ...       0.573      0\n",
              "...              ...                      ...  ...         ...    ...\n",
              "88075  1590568227882  2020-05-27T10:30:27.882  ...       0.417      5\n",
              "88076  1590568227887  2020-05-27T10:30:27.887  ...       0.412      5\n",
              "88077  1590568227892  2020-05-27T10:30:27.892  ...       0.405      5\n",
              "88078  1590568227897  2020-05-27T10:30:27.897  ...       0.396      5\n",
              "88079  1590568227902  2020-05-27T10:30:27.902  ...       0.389      5\n",
              "\n",
              "[88080 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfU-KEZJw-Hd"
      },
      "source": [
        "Per salvare il file completo su file csv..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1FhWn80iPI8"
      },
      "source": [
        "pathdir_read='/content/drive/MyDrive/Colab Notebooks/data/'\n",
        "df.to_csv(pathdir_read+'har_data.csv', encoding='utf-8', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YP9cpKb5GFGC"
      },
      "source": [
        "## <font color=\"red\">✪</font> Addestramento modello con libreria ML di Spark (spark.ml)\n",
        "\n",
        ">**NB:** spark.ml è la nuova libreria per machine learning rilasciata in Spark 2.0 evoluzione di spark.mllib che era presente in Spark 1.0\n",
        "\n",
        "NOTA:\n",
        ">Unfortunately, at this time, only **logistic/linear regression**, **decision trees**, **random forests** and **naive bayes** support **`multiclass classification`** in spark mllib/ml.  \n",
        "\n",
        "**Useremo quindi le Linear Regression e Random Forest**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO5gmmsLyNaP"
      },
      "source": [
        "####[SKIP] Normalizzazione del Dataframe Pandas \n",
        "\n",
        "Standardizzazione ovvero mettere le features in media nulla e dev std unitaria  \n",
        ">Verrà mostrato come effettuarla sia sul DF di Pandas che sul DF di pyspark on le librerie di spark.ml, ma non sembra inficiare i rusultati cosi' come avveniva con sklearn "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RMoUsIHyMbZ",
        "outputId": "86c25a11-40af-4818-a0f4-d6ca0ae57c93"
      },
      "source": [
        "X= df.iloc[:, :-1] # pandas df delle features\n",
        "Y= df.iloc[:, -1] # pandas series delle label\n",
        "# Scale the data to be between -1 and 1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "media = scaler.mean_\n",
        "stdDev = scaler.scale_\n",
        "print(\"X mean: \", scaler.mean_)\n",
        "print(\"X std dev (squadre root of variance): \", scaler.scale_)\n",
        "#X_df = X\n",
        "X = scaler.transform(X)\n",
        "# X = scaler.fit_transform(X)\n",
        "# # X e' ora un nparray, non piu' dataframe !!\n",
        "X\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X mean:  [-9.29320199e-17 -2.06515600e-16  1.03257800e-16]\n",
            "X std dev (squadre root of variance):  [1. 1. 1.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.4662742 ,  0.12768344, -0.36389215],\n",
              "       [-0.48984725,  0.10998886, -0.34100396],\n",
              "       [-0.48395399,  0.10114157, -0.3455816 ],\n",
              "       ...,\n",
              "       [-0.70495138, -0.07580424, -1.1283574 ],\n",
              "       [-0.70200475, -0.0227205 , -1.16955612],\n",
              "       [-0.70495138, -0.00502592, -1.20159958]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "EGbT-m0Ey-o3",
        "outputId": "f315e801-1485-47b3-f239-990e433724c6"
      },
      "source": [
        "# anziche' su X e Y posso rimettere tutto come nel df originale -> scaled_features_df\n",
        "from sklearn_pandas import DataFrameMapper\n",
        "\n",
        "mapper = DataFrameMapper([(df.columns, StandardScaler())])\n",
        "scaled_features = mapper.fit_transform(df.copy(), 4)\n",
        "scaled_features_df = pd.DataFrame(scaled_features, index=df.index, columns=df.columns)\n",
        "# rimetto la colonna delle label..al valore originale\n",
        "scaled_features_df['label'] = Y\n",
        "df = scaled_features_df\n",
        "df\n",
        "# per la standardizzazione si poteva usare MLlib: https://spark.apache.org/docs/latest/ml-features#standardscaler "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x-axis (g)</th>\n",
              "      <th>y-axis (g)</th>\n",
              "      <th>z-axis (g)</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.466274</td>\n",
              "      <td>0.127683</td>\n",
              "      <td>-0.363892</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.489847</td>\n",
              "      <td>0.109989</td>\n",
              "      <td>-0.341004</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.483954</td>\n",
              "      <td>0.101142</td>\n",
              "      <td>-0.345582</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.486901</td>\n",
              "      <td>0.092294</td>\n",
              "      <td>-0.373047</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.481007</td>\n",
              "      <td>0.118836</td>\n",
              "      <td>-0.359315</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88075</th>\n",
              "      <td>-0.663699</td>\n",
              "      <td>0.012669</td>\n",
              "      <td>-1.073426</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88076</th>\n",
              "      <td>-0.687272</td>\n",
              "      <td>-0.066957</td>\n",
              "      <td>-1.096314</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88077</th>\n",
              "      <td>-0.704951</td>\n",
              "      <td>-0.075804</td>\n",
              "      <td>-1.128357</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88078</th>\n",
              "      <td>-0.702005</td>\n",
              "      <td>-0.022721</td>\n",
              "      <td>-1.169556</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88079</th>\n",
              "      <td>-0.704951</td>\n",
              "      <td>-0.005026</td>\n",
              "      <td>-1.201600</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88080 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       x-axis (g)  y-axis (g)  z-axis (g)  label\n",
              "0       -0.466274    0.127683   -0.363892      0\n",
              "1       -0.489847    0.109989   -0.341004      0\n",
              "2       -0.483954    0.101142   -0.345582      0\n",
              "3       -0.486901    0.092294   -0.373047      0\n",
              "4       -0.481007    0.118836   -0.359315      0\n",
              "...           ...         ...         ...    ...\n",
              "88075   -0.663699    0.012669   -1.073426      5\n",
              "88076   -0.687272   -0.066957   -1.096314      5\n",
              "88077   -0.704951   -0.075804   -1.128357      5\n",
              "88078   -0.702005   -0.022721   -1.169556      5\n",
              "88079   -0.704951   -0.005026   -1.201600      5\n",
              "\n",
              "[88080 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3pJnH_QGujh"
      },
      "source": [
        "####<font color=\"red\">✪</font> Preparazione del dataset con ML lib di Spark\n",
        "\n",
        ">Per usare la ML lib di Spark per apprendimento supervisionato occorre trasformare il df in un vettore 2 colonne: 1 di features e 1 di label; quello delle features e' composto dai valori delle singole colonne separato da separatore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvYanjRztx6A",
        "outputId": "bf9a8514-ddfb-4e51-c123-9c92670546ce"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "df = pd.concat([sed, inp, sdr,cam,sce,sal], ignore_index=True) # commentare se si vuole usare il df scalato!!\n",
        "ds = spark.createDataFrame(data = df)\n",
        "ds.printSchema()\n",
        "ds.show(truncate=False)\n",
        "\n",
        "#Input all the features in one vector column\n",
        "assembler = VectorAssembler(inputCols=['x-axis (g)', 'y-axis (g)', 'z-axis (g)'], outputCol = 'features')\n",
        "\n",
        "output = assembler.transform(ds)\n",
        "\n",
        "#Input vs Output\n",
        "finalized_data = output.select(\"features\",\"label\")\n",
        "print(\"Assembled columns 'x-axis (g)', 'x-axis (g)', 'x-axis (g)' to vector column 'features'\")\n",
        "finalized_data.show(truncate=False)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- epoch (ms): long (nullable = true)\n",
            " |-- time (01:00): string (nullable = true)\n",
            " |-- elapsed (s): double (nullable = true)\n",
            " |-- x-axis (g): double (nullable = true)\n",
            " |-- y-axis (g): double (nullable = true)\n",
            " |-- z-axis (g): double (nullable = true)\n",
            " |-- label: long (nullable = true)\n",
            "\n",
            "+-------------+-----------------------+-----------+-------------------+--------------------+------------------+-----+\n",
            "|epoch (ms)   |time (01:00)           |elapsed (s)|x-axis (g)         |y-axis (g)          |z-axis (g)        |label|\n",
            "+-------------+-----------------------+-----------+-------------------+--------------------+------------------+-----+\n",
            "|1590567416332|2020-05-27T10:16:56.332|0.0        |-0.818             |-0.156              |0.5720000000000001|0    |\n",
            "|1590567416337|2020-05-27T10:16:56.337|0.005      |-0.826             |-0.158              |0.5770000000000001|0    |\n",
            "|1590567416342|2020-05-27T10:16:56.342|0.01       |-0.8240000000000001|-0.159              |0.5760000000000001|0    |\n",
            "|1590567416347|2020-05-27T10:16:56.347|0.015      |-0.825             |-0.16               |0.57              |0    |\n",
            "|1590567416352|2020-05-27T10:16:56.352|0.02       |-0.823             |-0.157              |0.573             |0    |\n",
            "|1590567416357|2020-05-27T10:16:56.357|0.025      |-0.823             |-0.16               |0.573             |0    |\n",
            "|1590567416362|2020-05-27T10:16:56.362|0.03       |-0.8270000000000001|-0.161              |0.574             |0    |\n",
            "|1590567416367|2020-05-27T10:16:56.367|0.035      |-0.8240000000000001|-0.159              |0.5720000000000001|0    |\n",
            "|1590567416372|2020-05-27T10:16:56.372|0.04       |-0.8240000000000001|-0.161              |0.5710000000000001|0    |\n",
            "|1590567416377|2020-05-27T10:16:56.377|0.045      |-0.8220000000000001|-0.159              |0.568             |0    |\n",
            "|1590567416382|2020-05-27T10:16:56.382|0.05       |-0.826             |-0.162              |0.5660000000000001|0    |\n",
            "|1590567416387|2020-05-27T10:16:56.387|0.055      |-0.826             |-0.16399999999999998|0.569             |0    |\n",
            "|1590567416392|2020-05-27T10:16:56.392|0.06       |-0.821             |-0.162              |0.5720000000000001|0    |\n",
            "|1590567416397|2020-05-27T10:16:56.397|0.065      |-0.823             |-0.165              |0.573             |0    |\n",
            "|1590567416402|2020-05-27T10:16:56.402|0.07       |-0.823             |-0.16               |0.573             |0    |\n",
            "|1590567416407|2020-05-27T10:16:56.407|0.075      |-0.825             |-0.162              |0.5760000000000001|0    |\n",
            "|1590567416412|2020-05-27T10:16:56.412|0.08       |-0.823             |-0.165              |0.574             |0    |\n",
            "|1590567416417|2020-05-27T10:16:56.417|0.085      |-0.8220000000000001|-0.163              |0.5710000000000001|0    |\n",
            "|1590567416422|2020-05-27T10:16:56.422|0.09       |-0.82              |-0.161              |0.574             |0    |\n",
            "|1590567416427|2020-05-27T10:16:56.427|0.095      |-0.8190000000000001|-0.16               |0.5720000000000001|0    |\n",
            "+-------------+-----------------------+-----------+-------------------+--------------------+------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n",
            "Assembled columns 'x-axis (g)', 'x-axis (g)', 'x-axis (g)' to vector column 'features'\n",
            "+-----------------------------------------------+-----+\n",
            "|features                                       |label|\n",
            "+-----------------------------------------------+-----+\n",
            "|[-0.818,-0.156,0.5720000000000001]             |0    |\n",
            "|[-0.826,-0.158,0.5770000000000001]             |0    |\n",
            "|[-0.8240000000000001,-0.159,0.5760000000000001]|0    |\n",
            "|[-0.825,-0.16,0.57]                            |0    |\n",
            "|[-0.823,-0.157,0.573]                          |0    |\n",
            "|[-0.823,-0.16,0.573]                           |0    |\n",
            "|[-0.8270000000000001,-0.161,0.574]             |0    |\n",
            "|[-0.8240000000000001,-0.159,0.5720000000000001]|0    |\n",
            "|[-0.8240000000000001,-0.161,0.5710000000000001]|0    |\n",
            "|[-0.8220000000000001,-0.159,0.568]             |0    |\n",
            "|[-0.826,-0.162,0.5660000000000001]             |0    |\n",
            "|[-0.826,-0.16399999999999998,0.569]            |0    |\n",
            "|[-0.821,-0.162,0.5720000000000001]             |0    |\n",
            "|[-0.823,-0.165,0.573]                          |0    |\n",
            "|[-0.823,-0.16,0.573]                           |0    |\n",
            "|[-0.825,-0.162,0.5760000000000001]             |0    |\n",
            "|[-0.823,-0.165,0.574]                          |0    |\n",
            "|[-0.8220000000000001,-0.163,0.5710000000000001]|0    |\n",
            "|[-0.82,-0.161,0.574]                           |0    |\n",
            "|[-0.8190000000000001,-0.16,0.5720000000000001] |0    |\n",
            "+-----------------------------------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bersI7KhF55r"
      },
      "source": [
        "per la normalizzazione possiamo usare lo StandardScaler di pyspark.ml [https://spark.apache.org/docs/latest/ml-features#standardscaler ]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYqY3H9hibiX",
        "outputId": "5feed14c-bedd-4dfe-9101-68d770cf6e98"
      },
      "source": [
        "from pyspark.ml.feature import StandardScaler\n",
        "\n",
        "dataFrame = finalized_data # finalized_data non scalato !!\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=True) ## NB withMean=True per avere media zero\n",
        "\n",
        "# Compute summary statistics by fitting the StandardScaler\n",
        "scalerModel = scaler.fit(dataFrame)\n",
        "\n",
        "# Normalize each feature to have unit standard deviation.\n",
        "scaledData = scalerModel.transform(dataFrame)\n",
        "scaledData.show(truncate=False)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------------------------+-----+---------------------------------------------------------------+\n",
            "|features                                       |label|scaledFeatures                                                 |\n",
            "+-----------------------------------------------+-----+---------------------------------------------------------------+\n",
            "|[-0.818,-0.156,0.5720000000000001]             |0    |[-0.4662715498012617,0.12768271190290903,-0.36389007980038346] |\n",
            "|[-0.826,-0.158,0.5770000000000001]             |0    |[-0.4898444715827734,0.10998823146701235,-0.3410020285345797]  |\n",
            "|[-0.8240000000000001,-0.159,0.5760000000000001]|0    |[-0.4839512411373958,0.10114099124906402,-0.34557963878774045] |\n",
            "|[-0.825,-0.16,0.57]                            |0    |[-0.4868978563600844,0.09229375103111567,-0.37304530030670546] |\n",
            "|[-0.823,-0.157,0.573]                          |0    |[-0.4810046259147065,0.1188354716849607,-0.35931246954722323]  |\n",
            "|[-0.823,-0.16,0.573]                           |0    |[-0.4810046259147065,0.09229375103111567,-0.35931246954722323] |\n",
            "|[-0.8270000000000001,-0.161,0.574]             |0    |[-0.4927910868054627,0.08344651081316734,-0.35473485929406245] |\n",
            "|[-0.8240000000000001,-0.159,0.5720000000000001]|0    |[-0.4839512411373958,0.10114099124906402,-0.36389007980038346] |\n",
            "|[-0.8240000000000001,-0.161,0.5710000000000001]|0    |[-0.4839512411373958,0.08344651081316734,-0.36846769005354424] |\n",
            "|[-0.8220000000000001,-0.159,0.568]             |0    |[-0.47805801069201787,0.10114099124906402,-0.38220052081302697]|\n",
            "|[-0.826,-0.162,0.5660000000000001]             |0    |[-0.4898444715827734,0.07459927059521901,-0.39135574131934797] |\n",
            "|[-0.826,-0.16399999999999998,0.569]            |0    |[-0.4898444715827734,0.05690479015932257,-0.37762291055986624] |\n",
            "|[-0.821,-0.162,0.5720000000000001]             |0    |[-0.47511139546932857,0.07459927059521901,-0.36389007980038346]|\n",
            "|[-0.823,-0.165,0.573]                          |0    |[-0.4810046259147065,0.048057549941373984,-0.35931246954722323]|\n",
            "|[-0.823,-0.16,0.573]                           |0    |[-0.4810046259147065,0.09229375103111567,-0.35931246954722323] |\n",
            "|[-0.825,-0.162,0.5760000000000001]             |0    |[-0.4868978563600844,0.07459927059521901,-0.34557963878774045] |\n",
            "|[-0.823,-0.165,0.574]                          |0    |[-0.4810046259147065,0.048057549941373984,-0.35473485929406245]|\n",
            "|[-0.8220000000000001,-0.163,0.5710000000000001]|0    |[-0.47805801069201787,0.06575203037727066,-0.36846769005354424]|\n",
            "|[-0.82,-0.161,0.574]                           |0    |[-0.4721647802466396,0.08344651081316734,-0.35473485929406245] |\n",
            "|[-0.8190000000000001,-0.16,0.5720000000000001] |0    |[-0.469218165023951,0.09229375103111567,-0.36389007980038346]  |\n",
            "+-----------------------------------------------+-----+---------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd2Tdmtk9oPm"
      },
      "source": [
        "###<font color=\"red\">✪</font>Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3L0i0X0pTno",
        "outputId": "b2948be6-c912-4cee-ee09-3efa7213b874"
      },
      "source": [
        "#Split training and testing data\n",
        "train_data,test_data = finalized_data.randomSplit([0.7,0.3])\n",
        "\n",
        "\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "print(\"import VectorAssembler e LinearRegression effettuato...\")\n",
        "regressor = LinearRegression(featuresCol = 'features', labelCol = 'label')\n",
        "\n",
        "#Learn to fit the model from training set\n",
        "regressor = regressor.fit(train_data)\n",
        "\n",
        "#To predict the prices on testing set\n",
        "pred = regressor.evaluate(test_data)\n",
        "\n",
        "#Predict the model\n",
        "pred.predictions.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "import VectorAssembler e LinearRegression effettuato...\n",
            "+--------------------+-----+------------------+\n",
            "|            features|label|        prediction|\n",
            "+--------------------+-----+------------------+\n",
            "|[-1.6626067682890...|    3|3.3081534623138715|\n",
            "|[-1.6449269765905...|    3|3.3923627301860604|\n",
            "|[-1.6095673931934...|    3|3.3888544562258227|\n",
            "|[-1.5565280180978...|    3| 3.352240774265952|\n",
            "|[-1.5093819069017...|    3|3.4457743566422763|\n",
            "|[-1.5005420110524...|    1|2.2257364513494777|\n",
            "|[-1.4828622193538...|    3| 3.259249662501487|\n",
            "|[-1.4710756915548...|    3| 3.279767623494943|\n",
            "|[-1.4475026359568...|    3| 3.343390079008718|\n",
            "|[-1.4091964206099...|    3|3.2771679648740144|\n",
            "|[-1.3856233650119...|    3|3.1779658606784236|\n",
            "|[-1.3708902052631...|    3| 3.418268781382448|\n",
            "|[-1.3090109343182...|    3| 3.024620447744475|\n",
            "|[-1.2824912467704...|    3|2.9796819323817205|\n",
            "|[-1.2677580870216...|    3| 3.149528795520894|\n",
            "|[-1.2589181911723...|    3| 3.388505704520693|\n",
            "|[-1.2441850314235...|    3|3.2633805164685574|\n",
            "|[-1.2412383994738...|    3| 3.241793944721378|\n",
            "|[-1.2353451355743...|    3| 3.075912604213925|\n",
            "|[-1.2176653438757...|    3|3.3347453158670417|\n",
            "+--------------------+-----+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eja1BLiaTThT",
        "outputId": "6f5bae7f-fd1b-4386-c4a0-22b3c9d61ff6"
      },
      "source": [
        "#coefficient of the regression model\n",
        "coeff = regressor.coefficients\n",
        "\n",
        "#X and Y intercept\n",
        "intr = regressor.intercept\n",
        "\n",
        "print (\"The coefficient of the model is : %a\" %coeff)\n",
        "print (\"The Intercept of the model is : %f\" %intr)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The coefficient of the model is : DenseVector([-0.3471, -0.1905, 0.5891])\n",
            "The Intercept of the model is : 2.657281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvjgJzCBvH0U",
        "outputId": "dbb9e37b-424b-41b8-f666-23c975c798eb"
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "eval = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "\n",
        "# Root Mean Square Error\n",
        "rmse = eval.evaluate(pred.predictions)\n",
        "print(\"RMSE: %.3f\" % rmse)\n",
        "\n",
        "# Mean Square Error\n",
        "mse = eval.evaluate(pred.predictions, {eval.metricName: \"mse\"})\n",
        "print(\"MSE: %.3f\" % mse)\n",
        "\n",
        "# Mean Absolute Error\n",
        "mae = eval.evaluate(pred.predictions, {eval.metricName: \"mae\"})\n",
        "print(\"MAE: %.3f\" % mae)\n",
        "\n",
        "# r2 - coefficient of determination\n",
        "r2 = eval.evaluate(pred.predictions, {eval.metricName: \"r2\"})\n",
        "print(\"r2: %.3f\" %r2)\n",
        "\n",
        "# RMSE: 1.756\n",
        "# MSE: 3.082\n",
        "# MAE: 1.537\n",
        "# r2: 0.000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 1.694\n",
            "MSE: 2.868\n",
            "MAE: 1.443\n",
            "r2: 0.070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgKY44I796if"
      },
      "source": [
        "### <font color=\"red\">✪</font> Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lKrwWRGvz4x",
        "outputId": "e988efe0-7d97-4968-c552-064cb112dc59"
      },
      "source": [
        "# https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "print(\"Librerie per RandomForestClssifier caricate..\")\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Librerie per RandomForestClssifier caricate..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nH-VjVCGmcn"
      },
      "source": [
        "####Training modello con vari numTrees e maxDepth (resto parametri al default)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Fyj2Q4ovqdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4340e315-273b-4af4-feee-5066288ea3ce"
      },
      "source": [
        "# Index labels, adding metadata to the label column.\n",
        "# Fit on whole dataset to include all labels in index.\n",
        "\n",
        "# sembra che non si possa fare a meno di indicizzare cosi' le lavel e le features..altrimenti da' errore e non se ne esce\n",
        "# https://stackoverflow.com/questions/33942519/cannot-run-randomforestclassifier-from-spark-ml-on-a-simple-example \n",
        "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(finalized_data)\n",
        "\n",
        "# Automatically identify categorical features, and index them.\n",
        "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
        "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(finalized_data)\n",
        "\n",
        "# Split the data into training and test sets (30% held out for testing)\n",
        "(trainingData, testData) = finalized_data.randomSplit([0.7, 0.3], seed = 1)\n",
        "\n",
        "# Train a RandomForest model.\n",
        "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=15, maxDepth=20, seed=1) \n",
        "# numTree 10 (8 sec. 75.6%), 30, 100 (23 sec 76.81%) , 200 (77.11% 1m23sec.)\n",
        "# numTree 10 e maxDepth=20 (82.20% 41sec.) seed=1\n",
        "# numTree 10 e maxDepth=25 (82.09% 35sec.) seed=1\n",
        "# numTree 15 e maxDepth=20 (82.36% 35sec.) seed=1 oltre finisce la RAM (>90%) 1m07s\n",
        "\n",
        "# Convert indexed labels back to original labels.\n",
        "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=labelIndexer.labels)\n",
        "\n",
        "# Chain indexers and forest in a Pipeline\n",
        "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
        "\n",
        "# Train model.  This also runs the indexers.\n",
        "model = pipeline.fit(trainingData)\n",
        "\n",
        "# Make predictions.\n",
        "predictions = model.transform(testData)\n",
        "\n",
        "# Select example rows to display.\n",
        "predictions.select(\"predictedLabel\", \"label\", \"features\").show(10)\n",
        "\n",
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(  labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
        "print(\"Accuracy = %g\" % (accuracy))\n",
        "\n",
        "rfModel = model.stages[2]\n",
        "print(rfModel)  # summary only\n",
        "# con NORMALIZZAZIONE:\n",
        "# Test Error = 0.231858\n",
        "# Accuracy = 0.768142\n",
        "# RandomForestClassificationModel: uid=RandomForestClassifier_a0dcb797bc18, numTrees=100, numClasses=6, numFeatures=3\n",
        "\n",
        "# valori default impurity='gini' o 'entropy'\n",
        "# class pyspark.ml.classification.RandomForestClassifier(*, featuresCol='features', labelCol='label', predictionCol='prediction',\n",
        "#   probabilityCol='probability', rawPredictionCol='rawPrediction', maxDepth=5, maxBins=32, minInstancesPerNode=1,\n",
        "#   minInfoGain=0.0, maxMemoryInMB=256, cacheNodeIds=False, checkpointInterval=10, impurity='gini', numTrees=20,\n",
        "#   featureSubsetStrategy='auto', seed=None, subsamplingRate=1.0, leafCol='', minWeightFractionPerNode=0.0, weightCol=None, \n",
        "#   bootstrap=True)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+-----+--------------------+\n",
            "|predictedLabel|label|            features|\n",
            "+--------------+-----+--------------------+\n",
            "|             3|    3|[-1.22,-0.249,0.665]|\n",
            "|             3|    3|[-1.218,-0.243,0....|\n",
            "|             5|    3|[-1.172,-0.381,0....|\n",
            "|             4|    3|[-1.171,-0.241000...|\n",
            "|             5|    3|[-1.17,-0.324,0.6...|\n",
            "|             5|    1|[-1.169,-0.171,0....|\n",
            "|             3|    3|[-1.168,-0.228999...|\n",
            "|             3|    3|[-1.13,-0.254,0.614]|\n",
            "|             5|    3|[-1.125,-0.293,0....|\n",
            "|             5|    3|[-1.125,-0.254,0....|\n",
            "+--------------+-----+--------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Test Error = 0.176321\n",
            "Accuracy = 0.823679\n",
            "RandomForestClassificationModel: uid=RandomForestClassifier_65a0a9eeb1b3, numTrees=15, numClasses=6, numFeatures=3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4e88xft-bDM"
      },
      "source": [
        "**Accuracy al 82.36% ... senza normalizzazione..**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQtSH-qAyA7u"
      },
      "source": [
        "####Training modello con tuning degli hyperparameter \n",
        "**..proviamo con hyperparameter tuning con la cross-fold validation**\n",
        ">la cvModel e' abbastanza instabile, vuole molta memoria, probabile memory leakage perche' non viene eseguita più di una volta senza riavviare il kernel..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxH_qY_9qe_W"
      },
      "source": [
        "# 1m45s e 11.84GB RAM con  2 soli parametri...\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(finalized_data)\n",
        "\n",
        "# Automatically identify categorical features, and index them.\n",
        "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
        "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(finalized_data)\n",
        "\n",
        "# Split the data into training and test sets (30% held out for testing)\n",
        "(trainingData, testData) = finalized_data.randomSplit([0.7, 0.3], seed = 1)\n",
        "\n",
        "# Convert indexed labels back to original labels.\n",
        "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=labelIndexer.labels)\n",
        "\n",
        "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", seed=1)\n",
        "# Chain indexers and forest in a Pipeline\n",
        "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
        "\n",
        "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [10]).addGrid(rf.maxDepth, [10, 25]).build()\n",
        "\n",
        "crossval = CrossValidator(estimator=pipeline,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=MulticlassClassificationEvaluator(),\n",
        "                          numFolds=2) \n",
        "# errore heap memory..incrementare .config(\"spark.memory.offHeap.size\",\"8g\")  \n",
        "# val spark = SparkSession\n",
        "#      .builder()\n",
        "#      .master(\"local[*]\")\n",
        "#      .config(\"spark.executor.memory\", \"70g\")\n",
        "#      .config(\"spark.driver.memory\", \"50g\")\n",
        "#      .config(\"spark.memory.offHeap.enabled\",true)\n",
        "#      .config(\"spark.memory.offHeap.size\",\"8g\")   \n",
        "#      .appName(\"sampleCodeForReference\")\n",
        "#      .getOrCreate()\n",
        "cvModel = crossval.fit(trainingData)\n",
        "\n",
        "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
        "predictions = cvModel.transform(testData)\n",
        "\n",
        "# valori default e parametri di RandomForestClassifier\n",
        "# class pyspark.ml.classification.RandomForestClassifier(*, featuresCol='features', labelCol='label', predictionCol='prediction', probabilityCol='probability', rawPredictionCol='rawPrediction', \\\n",
        "#     maxDepth=5, maxBins=32, minInstancesPerNode=1, minInfoGain=0.0, maxMemoryInMB=256, cacheNodeIds=False, checkpointInterval=10, impurity='gini', numTrees=20, featureSubsetStrategy='auto', \\\n",
        "#     seed=None, subsamplingRate=1.0, leafCol='', minWeightFractionPerNode=0.0, weightCol=None, bootstrap=True)[source"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrdWkzuZCMY4",
        "outputId": "b72b6ab7-b110-4da1-ebf5-9de8e6c4acfc"
      },
      "source": [
        "# Select example rows to display.\n",
        "predictions.select(\"predictedLabel\", \"label\", \"features\", \"prediction\", \"probability\", \"features\").show(5)\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+-----+--------------------+----------+--------------------+--------------------+\n",
            "|predictedLabel|label|            features|prediction|         probability|            features|\n",
            "+--------------+-----+--------------------+----------+--------------------+--------------------+\n",
            "|             3|    3|[-1.22,-0.249,0.665]|       2.0|[0.25275291159657...|[-1.22,-0.249,0.665]|\n",
            "|             3|    3|[-1.218,-0.243,0....|       2.0|[0.28534550418916...|[-1.218,-0.243,0....|\n",
            "|             5|    3|[-1.172,-0.381,0....|       0.0|[0.68795001295001...|[-1.172,-0.381,0....|\n",
            "|             4|    3|[-1.171,-0.241000...|       5.0|[0.26245682632779...|[-1.171,-0.241000...|\n",
            "|             5|    3|[-1.17,-0.324,0.6...|       0.0|[0.62739651416121...|[-1.17,-0.324,0.6...|\n",
            "+--------------+-----+--------------------+----------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeumIWPKEgf7",
        "outputId": "e8eaafd5-7565-46c5-b375-8ae597f843d3"
      },
      "source": [
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
        "print(\"Accuracy = %g\" % (accuracy))\n",
        "\n",
        "# Test Error = 0.174235\n",
        "# Accuracy = 0.825765 .. non si riesce a capire con quali parametri !!! con MaxDepth 10,100 e numTree 5,10,25, numFolds = 3, =>8m 42sec. \n",
        "\n",
        "# Test Error = 0.175942 ..con MaxDepth 10 e numTree 10, 25, umFolds = 2, =>1m 42sec. \n",
        "# Accuracy = 0.824058\n",
        "\n",
        "# Test Error = 0.179014\n",
        "# Accuracy = 0.820986 con seed=1"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Error = 0.176321\n",
            "Accuracy = 0.823679\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmmnZUFqvd__"
      },
      "source": [
        "**Accuracy al 82.09% ... con numTrees 10 e maxDepth 25.. (aumenta un poco aumentando numTrees)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvE47swkcruf",
        "outputId": "9568b371-c8cf-4a24-b0cd-4dcbf7fed165"
      },
      "source": [
        "print(type(predictions))\n",
        "print(type(testData))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n",
            "<class 'pyspark.sql.dataframe.DataFrame'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApHdx9T7si5C"
      },
      "source": [
        "#### Stampa gli hyperparameter del miglor modello trovato \n",
        "> sfido a trovare questa informazione !!! sembra un segreto di stato"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dipfuC8GrUdg",
        "outputId": "86c6b9ab-96a3-4e64-e573-1492d315d96d"
      },
      "source": [
        "bestPipeline = cvModel.bestModel\n",
        "bestLRModel = bestPipeline.stages[2]\n",
        "print('numTrees - ', bestLRModel.getNumTrees)\n",
        "print('maxDepth - ', bestLRModel.getOrDefault('maxDepth'))\n",
        "print('maxBins - ', bestLRModel.getOrDefault('maxBins'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "numTrees -  10\n",
            "maxDepth -  25\n",
            "maxBins -  32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEkGosvCtCw2"
      },
      "source": [
        ">Per la lista dei parametri che possono essere estratti prendere bestParams.name e passarlo alla bestLRModel.getOrDefault.  \n",
        "bestParams.doc fornisce una descrizione del parametro"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phpmA9roCEdt",
        "outputId": "d61140a6-0be8-4a7f-84a3-60ef07ccf2ba"
      },
      "source": [
        "bestParams = bestLRModel.extractParamMap()\n",
        "# print(type(bestParams))\n",
        "# for _ in bestParams:\n",
        "#   print(_.name, \":\", _.doc)\n",
        "\n",
        "# list(zip(cvModel.avgMetrics, paramGrid)) \n",
        "\n",
        "for _ in bestParams:\n",
        "  print(_.name, \" : \", bestLRModel.getOrDefault(_.name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bootstrap  :  True\n",
            "cacheNodeIds  :  False\n",
            "checkpointInterval  :  10\n",
            "featureSubsetStrategy  :  auto\n",
            "featuresCol  :  indexedFeatures\n",
            "impurity  :  gini\n",
            "labelCol  :  indexedLabel\n",
            "leafCol  :  \n",
            "maxBins  :  32\n",
            "maxDepth  :  25\n",
            "maxMemoryInMB  :  256\n",
            "minInfoGain  :  0.0\n",
            "minInstancesPerNode  :  1\n",
            "minWeightFractionPerNode  :  0.0\n",
            "numTrees  :  10\n",
            "predictionCol  :  prediction\n",
            "probabilityCol  :  probability\n",
            "rawPredictionCol  :  rawPrediction\n",
            "seed  :  1\n",
            "subsamplingRate  :  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp0cc3PWvvrY"
      },
      "source": [
        "###Info varie di backup (NON PRESENTARE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bccTEWAdGQPi"
      },
      "source": [
        "**qua usa map function per fare grid search**  \n",
        "Boosting Parallelism for ML in Python using scikit-learn, joblib & PySpark\n",
        "\n",
        "https://www.qubole.com/tech-blog/boosting-parallelism-for-ml-in-python-using-scikit-learn-joblib-pyspark/ \n",
        "https://grzegorzgajda.gitbooks.io/spark-examples/content/classification/rf-classification.html \n",
        "\n",
        "\n",
        "```\n",
        "val predictionsAndLabels = test.map {\n",
        "  point => (model.predict(point.features), point.label)\n",
        "}\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_-vkUsnHTlZ"
      },
      "source": [
        "Machine Learning Library (MLlib) Guide  \n",
        "https://spark.apache.org/docs/latest/ml-classification-regression.html#gradient-boosted-tree-classifier "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKlU7NPr6hnq"
      },
      "source": [
        "Unfortunately, at this time, only logistic regression, decision trees, random forests and naive bayes support multiclass classification in spark mllib/ml.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgYHU1fGCoz0"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\"\"\"\n",
        "Gradient Boosted Tree Classifier Example.\n",
        "\"\"\"\n",
        "data = finalized_data\n",
        "\n",
        "# Index labels, adding metadata to the label column.\n",
        "# Fit on whole dataset to include all labels in index.\n",
        "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
        "# Automatically identify categorical features, and index them.\n",
        "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
        "featureIndexer = VectorIndexer(inputCol=\"Attributes\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
        "\n",
        "# Split the data into training and test sets (30% held out for testing)\n",
        "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Train a GBT model.\n",
        "gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=10)\n",
        "\n",
        "# Chain indexers and GBT in a Pipeline\n",
        "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n",
        "\n",
        "# Train model.  This also runs the indexers.\n",
        "model = pipeline.fit(trainingData)\n",
        "\n",
        "# Make predictions.\n",
        "predictions = model.transform(testData)\n",
        "\n",
        "# Select example rows to display.\n",
        "predictions.select(\"prediction\", \"indexedLabel\", \"Attributes\").show(5)\n",
        "\n",
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
        "\n",
        "gbtModel = model.stages[2]\n",
        "print(gbtModel)  # summary only\n",
        "# $example off$"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUdFQsv67KDb"
      },
      "source": [
        "Logistic regression\n",
        "https://github.com/apache/spark/blob/master/examples/src/main/python/ml/logistic_regression_summary_example.py "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rg7ui8XY7MAZ"
      },
      "source": [
        "    from pyspark.ml.classification import LogisticRegression\n",
        "    data = finalized_data\n",
        "    (trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
        "    \n",
        "    lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
        "\n",
        "    # Fit the model\n",
        "    lrModel = lr.fit(trainingData)\n",
        "\n",
        "    # $example on$\n",
        "    # Extract the summary from the returned LogisticRegressionModel instance trained\n",
        "    # in the earlier example\n",
        "    trainingSummary = lrModel.summary\n",
        "\n",
        "    # Obtain the objective per iteration\n",
        "    objectiveHistory = trainingSummary.objectiveHistory\n",
        "    print(\"objectiveHistory:\")\n",
        "    for objective in objectiveHistory:\n",
        "        print(objective)\n",
        "\n",
        "    # Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
        "    trainingSummary.roc.show()\n",
        "    print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
        "\n",
        "    # Set the model threshold to maximize F-Measure\n",
        "    fMeasure = trainingSummary.fMeasureByThreshold\n",
        "    maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head()\n",
        "    bestThreshold = fMeasure.where(fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']) \\\n",
        "        .select('threshold').head()['threshold']\n",
        "    lr.setThreshold(bestThreshold)\n",
        "    # $example off$"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQwLTBrw6ZOv"
      },
      "source": [
        "#<font size=5 color=\"blue\">**Fase 2: Sviluppo modello di calcolo della classificazione della attività con Apache Spark secondo paradigma Map/Reduce**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHLtJlyP6-8E"
      },
      "source": [
        "Si vuole elaborare un modello di calcolo che a partire dai dati su file csv contenenti le accelerazione XYZ rilevate secondo un tempo di campionamento fissato (200Hz) appartenenti a diversi soggetti (identificati con id_persona) restituisca, per ciascuna persona, la classificazione per ciascun **secondo** di attività.\n",
        ">La classificazione per il secondo di attività viene attribuita secondo la regola del **plurarity vote rule** ovvero secondo la categoria più numerosa classificata nel secondo di attività in considerazione"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQM8VOrGF14B"
      },
      "source": [
        "###<font color=\"red\">✪</font>Import dei dati\n",
        "\n",
        "> **NB**: I dati sono genarati secondo la tecnica simile **data augumentation** [https://en.wikipedia.org/wiki/Data_augmentation] ovvero partendo da un dataset reale è stata aggiunta la colonna id_persona e per ciascun id_persona i dati delle accelerazioni XYZ sono prese dai dati originali di uno stesso soggetto ed alterati di una percentuale (+/-1%) secondo una funzione casuale. I dati così generati non sono usati per il trainign del modello al fine di ridurre la possibilità di overfitting così come per lo scopo pricipale della data augumentation ma per poter verificare l'efficacia del modello di calcolo con dati relativi a più soggetti creati artificiosamente.\n",
        "\n",
        "**Nota**: Sappiamo che i dati originali sono stati anche utilizzati per il training del modello e quindi i risultati non sono attendibili per la valutazione in assoluto della bontà del modello.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "3Lg-B6-2GhhM",
        "outputId": "1db779b2-6e4b-4eed-f0d7-e92873802d8f"
      },
      "source": [
        "# elimino colonna label e aggiungo id_persona\n",
        "df = df.iloc[:,:-1]\n",
        "df['id_persona'] = 0\n",
        "df"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch (ms)</th>\n",
              "      <th>time (01:00)</th>\n",
              "      <th>elapsed (s)</th>\n",
              "      <th>x-axis (g)</th>\n",
              "      <th>y-axis (g)</th>\n",
              "      <th>z-axis (g)</th>\n",
              "      <th>id_persona</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1590567416332</td>\n",
              "      <td>2020-05-27T10:16:56.332</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.818</td>\n",
              "      <td>-0.156</td>\n",
              "      <td>0.572</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1590567416337</td>\n",
              "      <td>2020-05-27T10:16:56.337</td>\n",
              "      <td>0.005</td>\n",
              "      <td>-0.826</td>\n",
              "      <td>-0.158</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1590567416342</td>\n",
              "      <td>2020-05-27T10:16:56.342</td>\n",
              "      <td>0.010</td>\n",
              "      <td>-0.824</td>\n",
              "      <td>-0.159</td>\n",
              "      <td>0.576</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1590567416347</td>\n",
              "      <td>2020-05-27T10:16:56.347</td>\n",
              "      <td>0.015</td>\n",
              "      <td>-0.825</td>\n",
              "      <td>-0.160</td>\n",
              "      <td>0.570</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1590567416352</td>\n",
              "      <td>2020-05-27T10:16:56.352</td>\n",
              "      <td>0.020</td>\n",
              "      <td>-0.823</td>\n",
              "      <td>-0.157</td>\n",
              "      <td>0.573</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88075</th>\n",
              "      <td>1590568227882</td>\n",
              "      <td>2020-05-27T10:30:27.882</td>\n",
              "      <td>96.840</td>\n",
              "      <td>-0.885</td>\n",
              "      <td>-0.169</td>\n",
              "      <td>0.417</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88076</th>\n",
              "      <td>1590568227887</td>\n",
              "      <td>2020-05-27T10:30:27.887</td>\n",
              "      <td>96.845</td>\n",
              "      <td>-0.893</td>\n",
              "      <td>-0.178</td>\n",
              "      <td>0.412</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88077</th>\n",
              "      <td>1590568227892</td>\n",
              "      <td>2020-05-27T10:30:27.892</td>\n",
              "      <td>96.850</td>\n",
              "      <td>-0.899</td>\n",
              "      <td>-0.179</td>\n",
              "      <td>0.405</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88078</th>\n",
              "      <td>1590568227897</td>\n",
              "      <td>2020-05-27T10:30:27.897</td>\n",
              "      <td>96.855</td>\n",
              "      <td>-0.898</td>\n",
              "      <td>-0.173</td>\n",
              "      <td>0.396</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88079</th>\n",
              "      <td>1590568227902</td>\n",
              "      <td>2020-05-27T10:30:27.902</td>\n",
              "      <td>96.860</td>\n",
              "      <td>-0.899</td>\n",
              "      <td>-0.171</td>\n",
              "      <td>0.389</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88080 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          epoch (ms)             time (01:00)  ...  z-axis (g)  id_persona\n",
              "0      1590567416332  2020-05-27T10:16:56.332  ...       0.572           0\n",
              "1      1590567416337  2020-05-27T10:16:56.337  ...       0.577           0\n",
              "2      1590567416342  2020-05-27T10:16:56.342  ...       0.576           0\n",
              "3      1590567416347  2020-05-27T10:16:56.347  ...       0.570           0\n",
              "4      1590567416352  2020-05-27T10:16:56.352  ...       0.573           0\n",
              "...              ...                      ...  ...         ...         ...\n",
              "88075  1590568227882  2020-05-27T10:30:27.882  ...       0.417           0\n",
              "88076  1590568227887  2020-05-27T10:30:27.887  ...       0.412           0\n",
              "88077  1590568227892  2020-05-27T10:30:27.892  ...       0.405           0\n",
              "88078  1590568227897  2020-05-27T10:30:27.897  ...       0.396           0\n",
              "88079  1590568227902  2020-05-27T10:30:27.902  ...       0.389           0\n",
              "\n",
              "[88080 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "k_wwjHsOdgxC",
        "outputId": "f5b8af1b-5f64-4117-e10c-347bcb32298e"
      },
      "source": [
        "\n",
        "import random as rnd\n",
        "rnd.seed(1)\n",
        "\n",
        "def genera_dati_per_persona(df, num_persone): # id_persona = 0 e' l'originale\n",
        "  df_orig = df.copy()\n",
        "  for i in range(1,num_persone+1):\n",
        "    df_temp = df_orig.copy()\n",
        "    df_temp['x-axis (g)'] = [round(x*rnd.randrange(10000,10100)/10000,3) for x in df_orig['x-axis (g)']]\n",
        "    df_temp['y-axis (g)'] = [round(x*rnd.randrange(10000,10100)/10000,3) for x in df_orig['y-axis (g)']]\n",
        "    df_temp['z-axis (g)'] = [round(x*rnd.randrange(10000,10100)/10000,3) for x in df_orig['z-axis (g)']]\n",
        "    df_temp['id_persona'] = i\n",
        "    frame = [df, df_temp]\n",
        "    df = pd.concat(frame, ignore_index=True )\n",
        "  return df\n",
        "\n",
        "df_augumented = genera_dati_per_persona(df, 1)\n",
        "\n",
        "df_augumented    "
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch (ms)</th>\n",
              "      <th>time (01:00)</th>\n",
              "      <th>elapsed (s)</th>\n",
              "      <th>x-axis (g)</th>\n",
              "      <th>y-axis (g)</th>\n",
              "      <th>z-axis (g)</th>\n",
              "      <th>id_persona</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1590567416332</td>\n",
              "      <td>2020-05-27T10:16:56.332</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.818</td>\n",
              "      <td>-0.156</td>\n",
              "      <td>0.572</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1590567416337</td>\n",
              "      <td>2020-05-27T10:16:56.337</td>\n",
              "      <td>0.005</td>\n",
              "      <td>-0.826</td>\n",
              "      <td>-0.158</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1590567416342</td>\n",
              "      <td>2020-05-27T10:16:56.342</td>\n",
              "      <td>0.010</td>\n",
              "      <td>-0.824</td>\n",
              "      <td>-0.159</td>\n",
              "      <td>0.576</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1590567416347</td>\n",
              "      <td>2020-05-27T10:16:56.347</td>\n",
              "      <td>0.015</td>\n",
              "      <td>-0.825</td>\n",
              "      <td>-0.160</td>\n",
              "      <td>0.570</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1590567416352</td>\n",
              "      <td>2020-05-27T10:16:56.352</td>\n",
              "      <td>0.020</td>\n",
              "      <td>-0.823</td>\n",
              "      <td>-0.157</td>\n",
              "      <td>0.573</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176155</th>\n",
              "      <td>1590568227882</td>\n",
              "      <td>2020-05-27T10:30:27.882</td>\n",
              "      <td>96.840</td>\n",
              "      <td>-0.893</td>\n",
              "      <td>-0.170</td>\n",
              "      <td>0.418</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176156</th>\n",
              "      <td>1590568227887</td>\n",
              "      <td>2020-05-27T10:30:27.887</td>\n",
              "      <td>96.845</td>\n",
              "      <td>-0.895</td>\n",
              "      <td>-0.179</td>\n",
              "      <td>0.415</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176157</th>\n",
              "      <td>1590568227892</td>\n",
              "      <td>2020-05-27T10:30:27.892</td>\n",
              "      <td>96.850</td>\n",
              "      <td>-0.907</td>\n",
              "      <td>-0.180</td>\n",
              "      <td>0.405</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176158</th>\n",
              "      <td>1590568227897</td>\n",
              "      <td>2020-05-27T10:30:27.897</td>\n",
              "      <td>96.855</td>\n",
              "      <td>-0.903</td>\n",
              "      <td>-0.174</td>\n",
              "      <td>0.400</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176159</th>\n",
              "      <td>1590568227902</td>\n",
              "      <td>2020-05-27T10:30:27.902</td>\n",
              "      <td>96.860</td>\n",
              "      <td>-0.906</td>\n",
              "      <td>-0.172</td>\n",
              "      <td>0.393</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>176160 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           epoch (ms)             time (01:00)  ...  z-axis (g)  id_persona\n",
              "0       1590567416332  2020-05-27T10:16:56.332  ...       0.572           0\n",
              "1       1590567416337  2020-05-27T10:16:56.337  ...       0.577           0\n",
              "2       1590567416342  2020-05-27T10:16:56.342  ...       0.576           0\n",
              "3       1590567416347  2020-05-27T10:16:56.347  ...       0.570           0\n",
              "4       1590567416352  2020-05-27T10:16:56.352  ...       0.573           0\n",
              "...               ...                      ...  ...         ...         ...\n",
              "176155  1590568227882  2020-05-27T10:30:27.882  ...       0.418           1\n",
              "176156  1590568227887  2020-05-27T10:30:27.887  ...       0.415           1\n",
              "176157  1590568227892  2020-05-27T10:30:27.892  ...       0.405           1\n",
              "176158  1590568227897  2020-05-27T10:30:27.897  ...       0.400           1\n",
              "176159  1590568227902  2020-05-27T10:30:27.902  ...       0.393           1\n",
              "\n",
              "[176160 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDIYBUlDeO4E"
      },
      "source": [
        "# per salvare i dati su file csv una volta generati..già fatto per 10 persone circa 29MB / 900k record... non eseguire\n",
        "# pathdir_read='/content/drive/MyDrive/Colab Notebooks/data/'\n",
        "# df_augumented.to_csv(pathdir_read+'har_augumented_data.csv', encoding='utf-8', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zchzQL1jF6-N"
      },
      "source": [
        "###Controllo e pulizia dei dati\n",
        "\n",
        "isNaN(), ecc.. ecc.. non ci sono dati non buoni e lasciamo dentro il dataset eventuali outlier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBz4RfogGI-8"
      },
      "source": [
        "###<font color=\"red\">✪</font> Creazione DataFrame Spark\n",
        "Trasformazione DataFrame pandas in un **Dataframe Spark** (in luogo dei **Resilient Distribudet Data (RDD)**, vedi Spark Dataframe vs Spark RDD https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html)  \n",
        "> I DataFrame Spark, introdotti con la ver. 2.0 di Spark, al pari delle RDD, sono strutture dati distribuite,  non è richiesto né è possibile usare la parallelize.  \n",
        "In generale le operazioni che possono essere effettuate su RDD hanno un equivalente per i DataFrame che p.e. hanno **select** o **selectExpr** per selezionare righe o **explode** in luogo della **flatMap** esistente per le RDD o ancora **collectAsList()**. E' ancor possibile usare le **map functions** ma occorre usare **df.rdd.map()** che effettua una conversione del DF in RDD perdendo i vantaggi del DF. Con i DF in luogo della **map()** si usa la **forEach()** per iterare su tutti gli elementi.  \n",
        "\n",
        "**Le trasformazioni PySpark con DataFrame sono più efficienti ed offrono più funzioni rispetto agli RDD (p.e. uso di SQL (come la select($nome_Col)), aggiunta colonne in modo semplice, ecc..). Inoltre le librerie per Machine Learning pyspark.ml hanno una serie di Transformers che operano direttamente sui DataFrame, così come la pyspark.mllib opera su RDD.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtIKs6VHOV5i",
        "outputId": "a10e6636-8159-4714-e807-f5de79c651e4"
      },
      "source": [
        "df_augumented.info()\n",
        "\n",
        "# devo aggiungere timestamp e id_persona\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 176160 entries, 0 to 176159\n",
            "Data columns (total 7 columns):\n",
            " #   Column        Non-Null Count   Dtype  \n",
            "---  ------        --------------   -----  \n",
            " 0   epoch (ms)    176160 non-null  int64  \n",
            " 1   time (01:00)  176160 non-null  object \n",
            " 2   elapsed (s)   176160 non-null  float64\n",
            " 3   x-axis (g)    176160 non-null  float64\n",
            " 4   y-axis (g)    176160 non-null  float64\n",
            " 5   z-axis (g)    176160 non-null  float64\n",
            " 6   id_persona    176160 non-null  int64  \n",
            "dtypes: float64(4), int64(2), object(1)\n",
            "memory usage: 9.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngp2ANzeM9eu",
        "outputId": "479f7b36-dec9-4c15-8f62-9018effc7247"
      },
      "source": [
        "ds = spark.createDataFrame(data = df_augumented)\n",
        "print(type(ds))\n",
        "ds.printSchema()\n",
        "ds.show(truncate=False)\n",
        "print(ds.head(5))\n",
        "print(ds.count())\n",
        "print(ds.take(3))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n",
            "root\n",
            " |-- epoch (ms): long (nullable = true)\n",
            " |-- time (01:00): string (nullable = true)\n",
            " |-- elapsed (s): double (nullable = true)\n",
            " |-- x-axis (g): double (nullable = true)\n",
            " |-- y-axis (g): double (nullable = true)\n",
            " |-- z-axis (g): double (nullable = true)\n",
            " |-- id_persona: long (nullable = true)\n",
            "\n",
            "+-------------+-----------------------+-----------+-------------------+--------------------+------------------+----------+\n",
            "|epoch (ms)   |time (01:00)           |elapsed (s)|x-axis (g)         |y-axis (g)          |z-axis (g)        |id_persona|\n",
            "+-------------+-----------------------+-----------+-------------------+--------------------+------------------+----------+\n",
            "|1590567416332|2020-05-27T10:16:56.332|0.0        |-0.818             |-0.156              |0.5720000000000001|0         |\n",
            "|1590567416337|2020-05-27T10:16:56.337|0.005      |-0.826             |-0.158              |0.5770000000000001|0         |\n",
            "|1590567416342|2020-05-27T10:16:56.342|0.01       |-0.8240000000000001|-0.159              |0.5760000000000001|0         |\n",
            "|1590567416347|2020-05-27T10:16:56.347|0.015      |-0.825             |-0.16               |0.57              |0         |\n",
            "|1590567416352|2020-05-27T10:16:56.352|0.02       |-0.823             |-0.157              |0.573             |0         |\n",
            "|1590567416357|2020-05-27T10:16:56.357|0.025      |-0.823             |-0.16               |0.573             |0         |\n",
            "|1590567416362|2020-05-27T10:16:56.362|0.03       |-0.8270000000000001|-0.161              |0.574             |0         |\n",
            "|1590567416367|2020-05-27T10:16:56.367|0.035      |-0.8240000000000001|-0.159              |0.5720000000000001|0         |\n",
            "|1590567416372|2020-05-27T10:16:56.372|0.04       |-0.8240000000000001|-0.161              |0.5710000000000001|0         |\n",
            "|1590567416377|2020-05-27T10:16:56.377|0.045      |-0.8220000000000001|-0.159              |0.568             |0         |\n",
            "|1590567416382|2020-05-27T10:16:56.382|0.05       |-0.826             |-0.162              |0.5660000000000001|0         |\n",
            "|1590567416387|2020-05-27T10:16:56.387|0.055      |-0.826             |-0.16399999999999998|0.569             |0         |\n",
            "|1590567416392|2020-05-27T10:16:56.392|0.06       |-0.821             |-0.162              |0.5720000000000001|0         |\n",
            "|1590567416397|2020-05-27T10:16:56.397|0.065      |-0.823             |-0.165              |0.573             |0         |\n",
            "|1590567416402|2020-05-27T10:16:56.402|0.07       |-0.823             |-0.16               |0.573             |0         |\n",
            "|1590567416407|2020-05-27T10:16:56.407|0.075      |-0.825             |-0.162              |0.5760000000000001|0         |\n",
            "|1590567416412|2020-05-27T10:16:56.412|0.08       |-0.823             |-0.165              |0.574             |0         |\n",
            "|1590567416417|2020-05-27T10:16:56.417|0.085      |-0.8220000000000001|-0.163              |0.5710000000000001|0         |\n",
            "|1590567416422|2020-05-27T10:16:56.422|0.09       |-0.82              |-0.161              |0.574             |0         |\n",
            "|1590567416427|2020-05-27T10:16:56.427|0.095      |-0.8190000000000001|-0.16               |0.5720000000000001|0         |\n",
            "+-------------+-----------------------+-----------+-------------------+--------------------+------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "[Row(epoch (ms)=1590567416332, time (01:00)='2020-05-27T10:16:56.332', elapsed (s)=0.0, x-axis (g)=-0.818, y-axis (g)=-0.156, z-axis (g)=0.5720000000000001, id_persona=0), Row(epoch (ms)=1590567416337, time (01:00)='2020-05-27T10:16:56.337', elapsed (s)=0.005, x-axis (g)=-0.826, y-axis (g)=-0.158, z-axis (g)=0.5770000000000001, id_persona=0), Row(epoch (ms)=1590567416342, time (01:00)='2020-05-27T10:16:56.342', elapsed (s)=0.01, x-axis (g)=-0.8240000000000001, y-axis (g)=-0.159, z-axis (g)=0.5760000000000001, id_persona=0), Row(epoch (ms)=1590567416347, time (01:00)='2020-05-27T10:16:56.347', elapsed (s)=0.015, x-axis (g)=-0.825, y-axis (g)=-0.16, z-axis (g)=0.57, id_persona=0), Row(epoch (ms)=1590567416352, time (01:00)='2020-05-27T10:16:56.352', elapsed (s)=0.02, x-axis (g)=-0.823, y-axis (g)=-0.157, z-axis (g)=0.573, id_persona=0)]\n",
            "176160\n",
            "[Row(epoch (ms)=1590567416332, time (01:00)='2020-05-27T10:16:56.332', elapsed (s)=0.0, x-axis (g)=-0.818, y-axis (g)=-0.156, z-axis (g)=0.5720000000000001, id_persona=0), Row(epoch (ms)=1590567416337, time (01:00)='2020-05-27T10:16:56.337', elapsed (s)=0.005, x-axis (g)=-0.826, y-axis (g)=-0.158, z-axis (g)=0.5770000000000001, id_persona=0), Row(epoch (ms)=1590567416342, time (01:00)='2020-05-27T10:16:56.342', elapsed (s)=0.01, x-axis (g)=-0.8240000000000001, y-axis (g)=-0.159, z-axis (g)=0.5760000000000001, id_persona=0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEXab2uBt5V9"
      },
      "source": [
        "###Alcuni funzioni di map e reduce con RDD, ma poi proseguiremo con i Dataframe Spark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iza9EFsmSTs_",
        "outputId": "94a947df-1bf9-42da-eb6c-6010bd549807"
      },
      "source": [
        "# https://stackoverflow.com/questions/29635776/can-i-convert-pandas-dataframe-to-spark-rdd/29640042\n",
        "# Il metodo parallelize di SparkContext creare una nuova RDD a partire da una collection, qua usiamo di dataframe\n",
        "# altrim dovevo trasformare pd dataframe in collection\n",
        "sparkRDD = ds.rdd.map(list)\n",
        "df_rdd = sparkRDD.collect()\n",
        "print(type(df_rdd))\n",
        "print(df_rdd[0:2])\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "[[1590567416332, '2020-05-27T10:16:56.332', 0.0, -0.818, -0.156, 0.5720000000000001, 0, 0], [1590567416337, '2020-05-27T10:16:56.337', 0.005, -0.826, -0.158, 0.5770000000000001, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr-Wwp2Unyur"
      },
      "source": [
        "# sparkRDD.map(lambda x: (x[0], x[1]))\\\n",
        "#     .groupByKey()\\\n",
        "#     .mapValues(lambda vals: len(set(vals)))\\\n",
        "#     .sortByKey()\\\n",
        "#     .collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SrGiKGLmae1"
      },
      "source": [
        "# ds2 = ds.rdd.map(lambda x: (x,1)).printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhWfQ8MXpeXz"
      },
      "source": [
        "# type(ds2)\n",
        "# ds2.printSchema()\n",
        "# ds2.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nax8YsJUGfeT"
      },
      "source": [
        "####Funzioni di MAP/REDUCE con RDD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69ShFJz6lBz3",
        "outputId": "7a776fb2-6ca5-41aa-c4fd-ac0fb7fc6ed1"
      },
      "source": [
        "print(sparkRDD.count())\n",
        "print(sparkRDD.first())\n",
        "print(sparkRDD.take(3))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "176160\n",
            "[1590567416332, '2020-05-27T10:16:56.332', 0.0, -0.818, -0.156, 0.5720000000000001, 0, 0]\n",
            "[[1590567416332, '2020-05-27T10:16:56.332', 0.0, -0.818, -0.156, 0.5720000000000001, 0, 0], [1590567416337, '2020-05-27T10:16:56.337', 0.005, -0.826, -0.158, 0.5770000000000001, 0, 0], [1590567416342, '2020-05-27T10:16:56.342', 0.01, -0.8240000000000001, -0.159, 0.5760000000000001, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnNZHo3blQ8V",
        "outputId": "3947259b-ee45-4028-a384-b47cf941ff8f"
      },
      "source": [
        "# def myfunc(x):\n",
        "#     if(x==0 or x==1 or x==2):\n",
        "#       return 'no_act'\n",
        "#     else:\n",
        "#       return 'act'\n",
        "# sparkRDD2 = sparkRDD.map(lambda x: (x,myfunc(x[3])))\n",
        "# print(sparkRDD2.first())\n",
        "# print(sparkRDD2.count())\n",
        "# print(sparkRDD.take(5))\n",
        "# print(sparkRDD2.take(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "([-0.818, -0.156, 0.5720000000000001, 0], 'no_act')\n",
            "88080\n",
            "[[-0.818, -0.156, 0.5720000000000001, 0], [-0.826, -0.158, 0.5770000000000001, 0], [-0.8240000000000001, -0.159, 0.5760000000000001, 0], [-0.825, -0.16, 0.57, 0], [-0.823, -0.157, 0.573, 0]]\n",
            "[([-0.818, -0.156, 0.5720000000000001, 0], 'no_act'), ([-0.826, -0.158, 0.5770000000000001, 0], 'no_act'), ([-0.8240000000000001, -0.159, 0.5760000000000001, 0], 'no_act'), ([-0.825, -0.16, 0.57, 0], 'no_act'), ([-0.823, -0.157, 0.573, 0], 'no_act')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG6HI8Zq4jbD"
      },
      "source": [
        "# sparkRDD3 = sparkRDD2.reduceByKey(lambda x,y: x+y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BeoagSULM8F",
        "outputId": "75239a7d-bab2-4972-edaa-79be035ca68b"
      },
      "source": [
        "# divido in modo binario le attività in no_act (inpiedi, sdraiato, seduto) e act (cammina, sale scende)\n",
        "def myfunc(x):\n",
        "    if(x==0 or x==1 or x==2):\n",
        "      return 'no_act'\n",
        "    else:\n",
        "      return 'act'\n",
        "sparkRDD3 = sparkRDD.map(lambda x: (myfunc(x[6]), 1))\n",
        "print(sparkRDD3.first())\n",
        "print(sparkRDD3.count())\n",
        "print(sparkRDD3.take(5))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('no_act', 1)\n",
            "176160\n",
            "[('no_act', 1), ('no_act', 1), ('no_act', 1), ('no_act', 1), ('no_act', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HNaP0k25mX4",
        "outputId": "6c1d9b6a-a900-4a83-e6aa-3620e589aac5"
      },
      "source": [
        "sparkRDD4 = sparkRDD3.reduceByKey(lambda x,y: x+y)\n",
        "\n",
        "for element in sparkRDD4.collect():\n",
        "    print(\"attività (key):\", element[0], \"\\t somma (val):\", element[1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attività (key): act \t somma (val): 92888\n",
            "attività (key): no_act \t somma (val): 83272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx9N_7BcdkkP",
        "outputId": "bdf2dfd5-2a94-4225-f69a-633a9db3dc24"
      },
      "source": [
        "sparkRDD5 = sparkRDD.map(lambda x: (x[7], 1)) # map per id_persona\n",
        "print(sparkRDD5.first())\n",
        "print(sparkRDD5.count())\n",
        "print(sparkRDD5.take(5))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 1)\n",
            "176160\n",
            "[(0, 1), (0, 1), (0, 1), (0, 1), (0, 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOdxb56HeDbZ",
        "outputId": "89d8b0d1-b092-46a2-d2c4-c52245aad923"
      },
      "source": [
        "sparkRDD6 = sparkRDD5.reduceByKey(lambda x,y: x+y)\n",
        "\n",
        "for element in sparkRDD6.collect():\n",
        "    print(\"id_persona (key):\", element[0], \"\\t somma (val):\", element[1])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id_persona (key): 0 \t somma (val): 88080\n",
            "id_persona (key): 1 \t somma (val): 88080\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEDQ-26vGkcS"
      },
      "source": [
        "###Predizione e classificazione con DataFrame\n",
        "\n",
        "<font color=\"red\">✪ </font>Eseguire prima il codice per addestrare il modello di classificazione (Random Forest) e di creazione Dataframe Spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6H44MIDf-fO"
      },
      "source": [
        "devo rendere il dataset compatibile con quello usato nella creazione del modello...che non aveva tutti i campi..usiamo la select()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRtbjR4zqVVL",
        "outputId": "ef0a0b83-fd78-4f96-f713-61321e9573ef"
      },
      "source": [
        "from pyspark.sql.functions import col\n",
        "new_ds = ds\n",
        "# new_ds = ds.filter(ds.label==0) # col('label') in luogo di new_ds.label \n",
        "new_ds.printSchema()\n",
        "print(new_ds.count())"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- epoch (ms): long (nullable = true)\n",
            " |-- time (01:00): string (nullable = true)\n",
            " |-- elapsed (s): double (nullable = true)\n",
            " |-- x-axis (g): double (nullable = true)\n",
            " |-- y-axis (g): double (nullable = true)\n",
            " |-- z-axis (g): double (nullable = true)\n",
            " |-- id_persona: long (nullable = true)\n",
            "\n",
            "176160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIH_imdftkk1"
      },
      "source": [
        "# Make predictions.\n",
        "#predictions = model.transform(testData)\n",
        "# testData.printSchema()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr_F2E-6t-dd",
        "outputId": "157938df-8d6f-44aa-c5b3-dbafcfe39c42"
      },
      "source": [
        "#Input all the features in one vector column\n",
        "assembler = VectorAssembler(inputCols=['x-axis (g)', 'y-axis (g)', 'z-axis (g)'], outputCol = 'features')\n",
        "output = assembler.transform(new_ds)\n",
        "#Input vs Output\n",
        "finalized_data = output.select(\"features\", \"epoch (ms)\", \"time (01:00)\", \"elapsed (s)\", \"id_persona\") # manca id_persona..me lo sono perso\n",
        "print(\"Assembled columns 'x-axis (g)', 'x-axis (g)', 'x-axis (g)' to vector column 'features'\")\n",
        "finalized_data.show(truncate=False)\n",
        "\n",
        "#labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(finalized_data)\n",
        "\n",
        "# Automatically identify categorical features, and index them.\n",
        "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
        "#featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(finalized_data)\n",
        "\n",
        "predictions = model.transform(finalized_data)\n",
        "predictions.show(truncate=False)\n",
        "\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Assembled columns 'x-axis (g)', 'x-axis (g)', 'x-axis (g)' to vector column 'features'\n",
            "+-----------------------------------------------+-------------+-----------------------+-----------+----------+\n",
            "|features                                       |epoch (ms)   |time (01:00)           |elapsed (s)|id_persona|\n",
            "+-----------------------------------------------+-------------+-----------------------+-----------+----------+\n",
            "|[-0.818,-0.156,0.5720000000000001]             |1590567416332|2020-05-27T10:16:56.332|0.0        |0         |\n",
            "|[-0.826,-0.158,0.5770000000000001]             |1590567416337|2020-05-27T10:16:56.337|0.005      |0         |\n",
            "|[-0.8240000000000001,-0.159,0.5760000000000001]|1590567416342|2020-05-27T10:16:56.342|0.01       |0         |\n",
            "|[-0.825,-0.16,0.57]                            |1590567416347|2020-05-27T10:16:56.347|0.015      |0         |\n",
            "|[-0.823,-0.157,0.573]                          |1590567416352|2020-05-27T10:16:56.352|0.02       |0         |\n",
            "|[-0.823,-0.16,0.573]                           |1590567416357|2020-05-27T10:16:56.357|0.025      |0         |\n",
            "|[-0.8270000000000001,-0.161,0.574]             |1590567416362|2020-05-27T10:16:56.362|0.03       |0         |\n",
            "|[-0.8240000000000001,-0.159,0.5720000000000001]|1590567416367|2020-05-27T10:16:56.367|0.035      |0         |\n",
            "|[-0.8240000000000001,-0.161,0.5710000000000001]|1590567416372|2020-05-27T10:16:56.372|0.04       |0         |\n",
            "|[-0.8220000000000001,-0.159,0.568]             |1590567416377|2020-05-27T10:16:56.377|0.045      |0         |\n",
            "|[-0.826,-0.162,0.5660000000000001]             |1590567416382|2020-05-27T10:16:56.382|0.05       |0         |\n",
            "|[-0.826,-0.16399999999999998,0.569]            |1590567416387|2020-05-27T10:16:56.387|0.055      |0         |\n",
            "|[-0.821,-0.162,0.5720000000000001]             |1590567416392|2020-05-27T10:16:56.392|0.06       |0         |\n",
            "|[-0.823,-0.165,0.573]                          |1590567416397|2020-05-27T10:16:56.397|0.065      |0         |\n",
            "|[-0.823,-0.16,0.573]                           |1590567416402|2020-05-27T10:16:56.402|0.07       |0         |\n",
            "|[-0.825,-0.162,0.5760000000000001]             |1590567416407|2020-05-27T10:16:56.407|0.075      |0         |\n",
            "|[-0.823,-0.165,0.574]                          |1590567416412|2020-05-27T10:16:56.412|0.08       |0         |\n",
            "|[-0.8220000000000001,-0.163,0.5710000000000001]|1590567416417|2020-05-27T10:16:56.417|0.085      |0         |\n",
            "|[-0.82,-0.161,0.574]                           |1590567416422|2020-05-27T10:16:56.422|0.09       |0         |\n",
            "|[-0.8190000000000001,-0.16,0.5720000000000001] |1590567416427|2020-05-27T10:16:56.427|0.095      |0         |\n",
            "+-----------------------------------------------+-------------+-----------------------+-----------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-----------------------------------------------+-------------+-----------------------+-----------+----------+-----------------------------------------------+--------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------+----------+--------------+\n",
            "|features                                       |epoch (ms)   |time (01:00)           |elapsed (s)|id_persona|indexedFeatures                                |rawPrediction                                                                               |probability                                                                                   |prediction|predictedLabel|\n",
            "+-----------------------------------------------+-------------+-----------------------+-----------+----------+-----------------------------------------------+--------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------+----------+--------------+\n",
            "|[-0.818,-0.156,0.5720000000000001]             |1590567416332|2020-05-27T10:16:56.332|0.0        |0         |[-0.818,-0.156,0.5720000000000001]             |[0.08721141317556559,0.0,0.016566435809886957,14.893851996541365,0.0,0.0023701544731837094] |[0.0058140942117043725,0.0,0.0011044290539924638,0.992923466436091,0.0,1.5801029821224728E-4] |3.0       |0             |\n",
            "|[-0.826,-0.158,0.5770000000000001]             |1590567416337|2020-05-27T10:16:56.337|0.005      |0         |[-0.826,-0.158,0.5770000000000001]             |[0.008982306903856546,0.0,0.0023781694157916956,14.985687145972966,0.0,0.002952377707386975]|[5.98820460257103E-4,0.0,1.5854462771944635E-4,0.9990458097315309,0.0,1.9682518049246497E-4]  |3.0       |0             |\n",
            "|[-0.8240000000000001,-0.159,0.5760000000000001]|1590567416342|2020-05-27T10:16:56.342|0.01       |0         |[-0.8240000000000001,-0.159,0.5760000000000001]|[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.825,-0.16,0.57]                            |1590567416347|2020-05-27T10:16:56.347|0.015      |0         |[-0.825,-0.16,0.57]                            |[0.008982306903856546,0.0,0.0023781694157916956,14.985687145972966,0.0,0.002952377707386975]|[5.98820460257103E-4,0.0,1.5854462771944635E-4,0.9990458097315309,0.0,1.9682518049246497E-4]  |3.0       |0             |\n",
            "|[-0.823,-0.157,0.573]                          |1590567416352|2020-05-27T10:16:56.352|0.02       |0         |[-0.823,-0.157,0.573]                          |[0.01976889810067727,0.0,0.002481928767633437,14.975173299670644,0.0,0.0025758734610462895] |[0.0013179265400451513,0.0,1.6546191784222913E-4,0.9983448866447096,0.0,1.7172489740308598E-4]|3.0       |0             |\n",
            "|[-0.823,-0.16,0.573]                           |1590567416357|2020-05-27T10:16:56.357|0.025      |0         |[-0.823,-0.16,0.573]                           |[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.8270000000000001,-0.161,0.574]             |1590567416362|2020-05-27T10:16:56.362|0.03       |0         |[-0.8270000000000001,-0.161,0.574]             |[0.008982306903856546,0.0,0.0023781694157916956,14.985687145972966,0.0,0.002952377707386975]|[5.98820460257103E-4,0.0,1.5854462771944635E-4,0.9990458097315309,0.0,1.9682518049246497E-4]  |3.0       |0             |\n",
            "|[-0.8240000000000001,-0.159,0.5720000000000001]|1590567416367|2020-05-27T10:16:56.367|0.035      |0         |[-0.8240000000000001,-0.159,0.5720000000000001]|[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.8240000000000001,-0.161,0.5710000000000001]|1590567416372|2020-05-27T10:16:56.372|0.04       |0         |[-0.8240000000000001,-0.161,0.5710000000000001]|[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.8220000000000001,-0.159,0.568]             |1590567416377|2020-05-27T10:16:56.377|0.045      |0         |[-0.8220000000000001,-0.159,0.568]             |[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.826,-0.162,0.5660000000000001]             |1590567416382|2020-05-27T10:16:56.382|0.05       |0         |[-0.826,-0.162,0.5660000000000001]             |[0.008982306903856546,0.0,0.0023781694157916956,14.985687145972966,0.0,0.002952377707386975]|[5.98820460257103E-4,0.0,1.5854462771944635E-4,0.9990458097315309,0.0,1.9682518049246497E-4]  |3.0       |0             |\n",
            "|[-0.826,-0.16399999999999998,0.569]            |1590567416387|2020-05-27T10:16:56.387|0.055      |0         |[-0.826,-0.16399999999999998,0.569]            |[0.008982306903856546,0.0,0.0023781694157916956,14.985687145972966,0.0,0.002952377707386975]|[5.98820460257103E-4,0.0,1.5854462771944635E-4,0.9990458097315309,0.0,1.9682518049246497E-4]  |3.0       |0             |\n",
            "|[-0.821,-0.162,0.5720000000000001]             |1590567416392|2020-05-27T10:16:56.392|0.06       |0         |[-0.821,-0.162,0.5720000000000001]             |[0.007402237615707589,0.0,0.0021257716368921495,14.985761700070706,0.0,0.004710290676693533]|[4.934825077138393E-4,0.0,1.4171810912614333E-4,0.9990507800047138,0.0,3.140193784462355E-4]  |3.0       |0             |\n",
            "|[-0.823,-0.165,0.573]                          |1590567416397|2020-05-27T10:16:56.397|0.065      |0         |[-0.823,-0.165,0.573]                          |[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.823,-0.16,0.573]                           |1590567416402|2020-05-27T10:16:56.402|0.07       |0         |[-0.823,-0.16,0.573]                           |[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.825,-0.162,0.5760000000000001]             |1590567416407|2020-05-27T10:16:56.407|0.075      |0         |[-0.825,-0.162,0.5760000000000001]             |[0.008982306903856546,0.0,0.0023781694157916956,14.985687145972966,0.0,0.002952377707386975]|[5.98820460257103E-4,0.0,1.5854462771944635E-4,0.9990458097315309,0.0,1.9682518049246497E-4]  |3.0       |0             |\n",
            "|[-0.823,-0.165,0.574]                          |1590567416412|2020-05-27T10:16:56.412|0.08       |0         |[-0.823,-0.165,0.574]                          |[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.8220000000000001,-0.163,0.5710000000000001]|1590567416417|2020-05-27T10:16:56.417|0.085      |0         |[-0.8220000000000001,-0.163,0.5710000000000001]|[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.82,-0.161,0.574]                           |1590567416422|2020-05-27T10:16:56.422|0.09       |0         |[-0.82,-0.161,0.574]                           |[0.007402237615707589,0.0,0.0021257716368921495,14.985761700070706,0.0,0.004710290676693533]|[4.934825077138393E-4,0.0,1.4171810912614333E-4,0.9990507800047138,0.0,3.140193784462355E-4]  |3.0       |0             |\n",
            "|[-0.8190000000000001,-0.16,0.5720000000000001] |1590567416427|2020-05-27T10:16:56.427|0.095      |0         |[-0.8190000000000001,-0.16,0.5720000000000001] |[0.007402237615707589,0.0,0.0021257716368921495,14.985761700070706,0.0,0.004710290676693533]|[4.934825077138393E-4,0.0,1.4171810912614333E-4,0.9990507800047138,0.0,3.140193784462355E-4]  |3.0       |0             |\n",
            "+-----------------------------------------------+-------------+-----------------------+-----------+----------+-----------------------------------------------+--------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------+----------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYrI4WCGtZLK",
        "outputId": "b5fa6d3b-69d8-4938-8f7e-a1b58f154b22"
      },
      "source": [
        "predictions.show(truncate=False)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------------------------+-------------+-----------------------+-----------+----------+-----------------------------------------------+--------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------+----------+--------------+\n",
            "|features                                       |epoch (ms)   |time (01:00)           |elapsed (s)|id_persona|indexedFeatures                                |rawPrediction                                                                               |probability                                                                                   |prediction|predictedLabel|\n",
            "+-----------------------------------------------+-------------+-----------------------+-----------+----------+-----------------------------------------------+--------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------+----------+--------------+\n",
            "|[-0.818,-0.156,0.5720000000000001]             |1590567416332|2020-05-27T10:16:56.332|0.0        |0         |[-0.818,-0.156,0.5720000000000001]             |[0.08721141317556559,0.0,0.016566435809886957,14.893851996541365,0.0,0.0023701544731837094] |[0.0058140942117043725,0.0,0.0011044290539924638,0.992923466436091,0.0,1.5801029821224728E-4] |3.0       |0             |\n",
            "|[-0.826,-0.158,0.5770000000000001]             |1590567416337|2020-05-27T10:16:56.337|0.005      |0         |[-0.826,-0.158,0.5770000000000001]             |[0.008982306903856546,0.0,0.0023781694157916956,14.985687145972966,0.0,0.002952377707386975]|[5.98820460257103E-4,0.0,1.5854462771944635E-4,0.9990458097315309,0.0,1.9682518049246497E-4]  |3.0       |0             |\n",
            "|[-0.8240000000000001,-0.159,0.5760000000000001]|1590567416342|2020-05-27T10:16:56.342|0.01       |0         |[-0.8240000000000001,-0.159,0.5760000000000001]|[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.825,-0.16,0.57]                            |1590567416347|2020-05-27T10:16:56.347|0.015      |0         |[-0.825,-0.16,0.57]                            |[0.008982306903856546,0.0,0.0023781694157916956,14.985687145972966,0.0,0.002952377707386975]|[5.98820460257103E-4,0.0,1.5854462771944635E-4,0.9990458097315309,0.0,1.9682518049246497E-4]  |3.0       |0             |\n",
            "|[-0.823,-0.157,0.573]                          |1590567416352|2020-05-27T10:16:56.352|0.02       |0         |[-0.823,-0.157,0.573]                          |[0.01976889810067727,0.0,0.002481928767633437,14.975173299670644,0.0,0.0025758734610462895] |[0.0013179265400451513,0.0,1.6546191784222913E-4,0.9983448866447096,0.0,1.7172489740308598E-4]|3.0       |0             |\n",
            "|[-0.823,-0.16,0.573]                           |1590567416357|2020-05-27T10:16:56.357|0.025      |0         |[-0.823,-0.16,0.573]                           |[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.8270000000000001,-0.161,0.574]             |1590567416362|2020-05-27T10:16:56.362|0.03       |0         |[-0.8270000000000001,-0.161,0.574]             |[0.008982306903856546,0.0,0.0023781694157916956,14.985687145972966,0.0,0.002952377707386975]|[5.98820460257103E-4,0.0,1.5854462771944635E-4,0.9990458097315309,0.0,1.9682518049246497E-4]  |3.0       |0             |\n",
            "|[-0.8240000000000001,-0.159,0.5720000000000001]|1590567416367|2020-05-27T10:16:56.367|0.035      |0         |[-0.8240000000000001,-0.159,0.5720000000000001]|[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.8240000000000001,-0.161,0.5710000000000001]|1590567416372|2020-05-27T10:16:56.372|0.04       |0         |[-0.8240000000000001,-0.161,0.5710000000000001]|[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.8220000000000001,-0.159,0.568]             |1590567416377|2020-05-27T10:16:56.377|0.045      |0         |[-0.8220000000000001,-0.159,0.568]             |[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.826,-0.162,0.5660000000000001]             |1590567416382|2020-05-27T10:16:56.382|0.05       |0         |[-0.826,-0.162,0.5660000000000001]             |[0.008982306903856546,0.0,0.0023781694157916956,14.985687145972966,0.0,0.002952377707386975]|[5.98820460257103E-4,0.0,1.5854462771944635E-4,0.9990458097315309,0.0,1.9682518049246497E-4]  |3.0       |0             |\n",
            "|[-0.826,-0.16399999999999998,0.569]            |1590567416387|2020-05-27T10:16:56.387|0.055      |0         |[-0.826,-0.16399999999999998,0.569]            |[0.008982306903856546,0.0,0.0023781694157916956,14.985687145972966,0.0,0.002952377707386975]|[5.98820460257103E-4,0.0,1.5854462771944635E-4,0.9990458097315309,0.0,1.9682518049246497E-4]  |3.0       |0             |\n",
            "|[-0.821,-0.162,0.5720000000000001]             |1590567416392|2020-05-27T10:16:56.392|0.06       |0         |[-0.821,-0.162,0.5720000000000001]             |[0.007402237615707589,0.0,0.0021257716368921495,14.985761700070706,0.0,0.004710290676693533]|[4.934825077138393E-4,0.0,1.4171810912614333E-4,0.9990507800047138,0.0,3.140193784462355E-4]  |3.0       |0             |\n",
            "|[-0.823,-0.165,0.573]                          |1590567416397|2020-05-27T10:16:56.397|0.065      |0         |[-0.823,-0.165,0.573]                          |[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.823,-0.16,0.573]                           |1590567416402|2020-05-27T10:16:56.402|0.07       |0         |[-0.823,-0.16,0.573]                           |[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.825,-0.162,0.5760000000000001]             |1590567416407|2020-05-27T10:16:56.407|0.075      |0         |[-0.825,-0.162,0.5760000000000001]             |[0.008982306903856546,0.0,0.0023781694157916956,14.985687145972966,0.0,0.002952377707386975]|[5.98820460257103E-4,0.0,1.5854462771944635E-4,0.9990458097315309,0.0,1.9682518049246497E-4]  |3.0       |0             |\n",
            "|[-0.823,-0.165,0.574]                          |1590567416412|2020-05-27T10:16:56.412|0.08       |0         |[-0.823,-0.165,0.574]                          |[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.8220000000000001,-0.163,0.5710000000000001]|1590567416417|2020-05-27T10:16:56.417|0.085      |0         |[-0.8220000000000001,-0.163,0.5710000000000001]|[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.82,-0.161,0.574]                           |1590567416422|2020-05-27T10:16:56.422|0.09       |0         |[-0.82,-0.161,0.574]                           |[0.007402237615707589,0.0,0.0021257716368921495,14.985761700070706,0.0,0.004710290676693533]|[4.934825077138393E-4,0.0,1.4171810912614333E-4,0.9990507800047138,0.0,3.140193784462355E-4]  |3.0       |0             |\n",
            "|[-0.8190000000000001,-0.16,0.5720000000000001] |1590567416427|2020-05-27T10:16:56.427|0.095      |0         |[-0.8190000000000001,-0.16,0.5720000000000001] |[0.007402237615707589,0.0,0.0021257716368921495,14.985761700070706,0.0,0.004710290676693533]|[4.934825077138393E-4,0.0,1.4171810912614333E-4,0.9990507800047138,0.0,3.140193784462355E-4]  |3.0       |0             |\n",
            "+-----------------------------------------------+-------------+-----------------------+-----------+----------+-----------------------------------------------+--------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------+----------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhBowHASm4Qy",
        "outputId": "5e4ff11e-783f-40ec-d5c9-1dcb096af304"
      },
      "source": [
        "# projection = predictions.select(\"id_persona\", \"label\", \"predictedLabel\" )\n",
        "# projection.show(truncate=False)\n",
        "predictions.select(\"id_persona\", \"predictedLabel\" ).show(truncate=False)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+--------------+\n",
            "|id_persona|predictedLabel|\n",
            "+----------+--------------+\n",
            "|0         |0             |\n",
            "|0         |0             |\n",
            "|0         |0             |\n",
            "|0         |0             |\n",
            "|0         |0             |\n",
            "|0         |0             |\n",
            "|0         |0             |\n",
            "|0         |0             |\n",
            "|0         |0             |\n",
            "|0         |0             |\n",
            "|0         |0             |\n",
            "|0         |0             |\n",
            "|0         |0             |\n",
            "|0         |0             |\n",
            "|0         |0             |\n",
            "|0         |0             |\n",
            "|0         |0             |\n",
            "|0         |0             |\n",
            "|0         |0             |\n",
            "|0         |0             |\n",
            "+----------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E47s8rQuww5d"
      },
      "source": [
        "<font color=\"red\">✪ </font>Stampa dei risultati per Persona e per Attività (classe)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdtpcm4bxaEF",
        "outputId": "3e308e10-add2-46ee-b061-712622df8e6c"
      },
      "source": [
        "# print(\"predict as class 0 for id_person 0: \", predictions.select(\"predictedLabel\", \"id_persona\").where((col('predictedLabel')==0) & (col('id_persona')==0)).count())\n",
        "# print(\"predict as class 1 for id_person 0: \", predictions.select(\"predictedLabel\", \"id_persona\").where((col('predictedLabel')==1) & (col('id_persona')==0)).count())\n",
        "# print(\"predict as class 2:\", predictions.select(\"predictedLabel\", \"features\").where(col('predictedLabel')==2).count())\n",
        "# print(\"predict as class 3:\", predictions.select(\"predictedLabel\", \"features\").where(col('predictedLabel')==3).count())\n",
        "# print(\"predict as class 4:\", predictions.select(\"predictedLabel\", \"features\").where(col('predictedLabel')==4).count())\n",
        "# print(\"predict as class 5:\", predictions.select(\"predictedLabel\", \"features\").where(col('predictedLabel')==5).count())\n",
        "# print(\"on total of :\", new_ds.count())\n",
        "num_persone = predictions.select(\"id_persona\").distinct().count()\n",
        "for j in range(num_persone):\n",
        "  print(\"Predicted classes for id_person {}:\".format(j))\n",
        "  for i in range(6):  \n",
        "    print(\"\\t# samples predicted in class {}: \".format(i), predictions.select(\"predictedLabel\", \"id_persona\").where((col('predictedLabel')==i) & (col('id_persona')==j)).count())\n",
        "print(\"on total of :\", new_ds.count())"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted classes for id_person 0:\n",
            "\t# samples predicted in class 0:  13784\n",
            "\t# samples predicted in class 1:  13568\n",
            "\t# samples predicted in class 2:  14523\n",
            "\t# samples predicted in class 3:  15724\n",
            "\t# samples predicted in class 4:  11934\n",
            "\t# samples predicted in class 5:  18547\n",
            "Predicted classes for id_person 1:\n",
            "\t# samples predicted in class 0:  13521\n",
            "\t# samples predicted in class 1:  13544\n",
            "\t# samples predicted in class 2:  14528\n",
            "\t# samples predicted in class 3:  15871\n",
            "\t# samples predicted in class 4:  11937\n",
            "\t# samples predicted in class 5:  18679\n",
            "on total of : 176160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW8vH-qkvMMr",
        "outputId": "b636887e-faca-43f4-bf83-723a87fa3680"
      },
      "source": [
        "i=0; j=1;\n",
        "print(\"predict as class {} for id_person {}: \".format(i,j))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predict as class 0 for id_person 1: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTYa0n4KrqJ7",
        "outputId": "929cd941-906b-4743-c252-f31fdd103984"
      },
      "source": [
        "predictions.select(\"id_persona\").distinct().count()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buwIexRb3CjO"
      },
      "source": [
        "Modifico colonna time per poter raggruppare in un secondo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUjbB2Gk3C-b",
        "outputId": "5c9a0194-5cc0-4974-ba24-e196699373ed"
      },
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "predictions = predictions.withColumn(\"time (01:00)\", predictions['time (01:00)'].substr(0, 19))\n",
        "predictions.show(truncate=False)\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------------------------+-------------+-------------------+-----------+----------+-----------------------------------------------+--------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------+----------+--------------+\n",
            "|features                                       |epoch (ms)   |time (01:00)       |elapsed (s)|id_persona|indexedFeatures                                |rawPrediction                                                                               |probability                                                                                   |prediction|predictedLabel|\n",
            "+-----------------------------------------------+-------------+-------------------+-----------+----------+-----------------------------------------------+--------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------+----------+--------------+\n",
            "|[-0.818,-0.156,0.5720000000000001]             |1590567416332|2020-05-27T10:16:56|0.0        |0         |[-0.818,-0.156,0.5720000000000001]             |[0.08721141317556559,0.0,0.016566435809886957,14.893851996541365,0.0,0.0023701544731837094] |[0.0058140942117043725,0.0,0.0011044290539924638,0.992923466436091,0.0,1.5801029821224728E-4] |3.0       |0             |\n",
            "|[-0.826,-0.158,0.5770000000000001]             |1590567416337|2020-05-27T10:16:56|0.005      |0         |[-0.826,-0.158,0.5770000000000001]             |[0.008982306903856546,0.0,0.0023781694157916956,14.985687145972966,0.0,0.002952377707386975]|[5.98820460257103E-4,0.0,1.5854462771944635E-4,0.9990458097315309,0.0,1.9682518049246497E-4]  |3.0       |0             |\n",
            "|[-0.8240000000000001,-0.159,0.5760000000000001]|1590567416342|2020-05-27T10:16:56|0.01       |0         |[-0.8240000000000001,-0.159,0.5760000000000001]|[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.825,-0.16,0.57]                            |1590567416347|2020-05-27T10:16:56|0.015      |0         |[-0.825,-0.16,0.57]                            |[0.008982306903856546,0.0,0.0023781694157916956,14.985687145972966,0.0,0.002952377707386975]|[5.98820460257103E-4,0.0,1.5854462771944635E-4,0.9990458097315309,0.0,1.9682518049246497E-4]  |3.0       |0             |\n",
            "|[-0.823,-0.157,0.573]                          |1590567416352|2020-05-27T10:16:56|0.02       |0         |[-0.823,-0.157,0.573]                          |[0.01976889810067727,0.0,0.002481928767633437,14.975173299670644,0.0,0.0025758734610462895] |[0.0013179265400451513,0.0,1.6546191784222913E-4,0.9983448866447096,0.0,1.7172489740308598E-4]|3.0       |0             |\n",
            "|[-0.823,-0.16,0.573]                           |1590567416357|2020-05-27T10:16:56|0.025      |0         |[-0.823,-0.16,0.573]                           |[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.8270000000000001,-0.161,0.574]             |1590567416362|2020-05-27T10:16:56|0.03       |0         |[-0.8270000000000001,-0.161,0.574]             |[0.008982306903856546,0.0,0.0023781694157916956,14.985687145972966,0.0,0.002952377707386975]|[5.98820460257103E-4,0.0,1.5854462771944635E-4,0.9990458097315309,0.0,1.9682518049246497E-4]  |3.0       |0             |\n",
            "|[-0.8240000000000001,-0.159,0.5720000000000001]|1590567416367|2020-05-27T10:16:56|0.035      |0         |[-0.8240000000000001,-0.159,0.5720000000000001]|[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.8240000000000001,-0.161,0.5710000000000001]|1590567416372|2020-05-27T10:16:56|0.04       |0         |[-0.8240000000000001,-0.161,0.5710000000000001]|[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.8220000000000001,-0.159,0.568]             |1590567416377|2020-05-27T10:16:56|0.045      |0         |[-0.8220000000000001,-0.159,0.568]             |[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.826,-0.162,0.5660000000000001]             |1590567416382|2020-05-27T10:16:56|0.05       |0         |[-0.826,-0.162,0.5660000000000001]             |[0.008982306903856546,0.0,0.0023781694157916956,14.985687145972966,0.0,0.002952377707386975]|[5.98820460257103E-4,0.0,1.5854462771944635E-4,0.9990458097315309,0.0,1.9682518049246497E-4]  |3.0       |0             |\n",
            "|[-0.826,-0.16399999999999998,0.569]            |1590567416387|2020-05-27T10:16:56|0.055      |0         |[-0.826,-0.16399999999999998,0.569]            |[0.008982306903856546,0.0,0.0023781694157916956,14.985687145972966,0.0,0.002952377707386975]|[5.98820460257103E-4,0.0,1.5854462771944635E-4,0.9990458097315309,0.0,1.9682518049246497E-4]  |3.0       |0             |\n",
            "|[-0.821,-0.162,0.5720000000000001]             |1590567416392|2020-05-27T10:16:56|0.06       |0         |[-0.821,-0.162,0.5720000000000001]             |[0.007402237615707589,0.0,0.0021257716368921495,14.985761700070706,0.0,0.004710290676693533]|[4.934825077138393E-4,0.0,1.4171810912614333E-4,0.9990507800047138,0.0,3.140193784462355E-4]  |3.0       |0             |\n",
            "|[-0.823,-0.165,0.573]                          |1590567416397|2020-05-27T10:16:56|0.065      |0         |[-0.823,-0.165,0.573]                          |[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.823,-0.16,0.573]                           |1590567416402|2020-05-27T10:16:56|0.07       |0         |[-0.823,-0.16,0.573]                           |[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.825,-0.162,0.5760000000000001]             |1590567416407|2020-05-27T10:16:56|0.075      |0         |[-0.825,-0.162,0.5760000000000001]             |[0.008982306903856546,0.0,0.0023781694157916956,14.985687145972966,0.0,0.002952377707386975]|[5.98820460257103E-4,0.0,1.5854462771944635E-4,0.9990458097315309,0.0,1.9682518049246497E-4]  |3.0       |0             |\n",
            "|[-0.823,-0.165,0.574]                          |1590567416412|2020-05-27T10:16:56|0.08       |0         |[-0.823,-0.165,0.574]                          |[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.8220000000000001,-0.163,0.5710000000000001]|1590567416417|2020-05-27T10:16:56|0.085      |0         |[-0.8220000000000001,-0.163,0.5710000000000001]|[0.010434739728838387,0.0,0.0023781694157916956,14.984234713147982,0.0,0.002952377707386975]|[6.956493152558925E-4,0.0,1.5854462771944637E-4,0.9989489808765322,0.0,1.96825180492465E-4]   |3.0       |0             |\n",
            "|[-0.82,-0.161,0.574]                           |1590567416422|2020-05-27T10:16:56|0.09       |0         |[-0.82,-0.161,0.574]                           |[0.007402237615707589,0.0,0.0021257716368921495,14.985761700070706,0.0,0.004710290676693533]|[4.934825077138393E-4,0.0,1.4171810912614333E-4,0.9990507800047138,0.0,3.140193784462355E-4]  |3.0       |0             |\n",
            "|[-0.8190000000000001,-0.16,0.5720000000000001] |1590567416427|2020-05-27T10:16:56|0.095      |0         |[-0.8190000000000001,-0.16,0.5720000000000001] |[0.007402237615707589,0.0,0.0021257716368921495,14.985761700070706,0.0,0.004710290676693533]|[4.934825077138393E-4,0.0,1.4171810912614333E-4,0.9990507800047138,0.0,3.140193784462355E-4]  |3.0       |0             |\n",
            "+-----------------------------------------------+-------------+-------------------+-----------+----------+-----------------------------------------------+--------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------+----------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ub71swMKGmfq"
      },
      "source": [
        "###Funzione di reduce e classificazione"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH0_dqRUyzUc"
      },
      "source": [
        "# predictions.select(\"predictedLabel\", \"id_persona\", \"time (01:00)\").where( (col('id_persona')==0)).orderBy(col('time (01:00)'))\\\n",
        "#   .groupBy(col('time (01:00)'),col('predictedLabel')).agg(count(lit(1)).alias(\"Num Of Records\")).show(truncate=False)\n",
        "\n",
        "df_sorted_per_second = predictions.select(\"predictedLabel\", \"id_persona\", \"time (01:00)\")\\\n",
        "  .groupBy(col('id_persona'), col('time (01:00)'),col('predictedLabel')).agg(count(lit(1)).alias(\"Num Of Records\")).orderBy(col('id_persona'),col('time (01:00)'))\n",
        "\n",
        "# https://stackoverflow.com/questions/34249841/spark-dataframe-reducebykey-like-operation\n",
        "# df.registerTempTable(\"df\")\n",
        "# sqlContext.sql(\"SELECT key, SUM(value) AS value FROM df GROUP BY key\")\n",
        "\n",
        "# https://sparkbyexamples.com/pyspark/pyspark-count-distinct-from-dataframe/\n",
        "# df.createOrReplaceTempView(\"EMP\")\n",
        "# spark.sql(\"select distinct(count(*)) from EMP\").show()"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3sPvf3f7w_v",
        "outputId": "516325b0-bca1-4be8-d6ec-3300dbd02d7c"
      },
      "source": [
        "type(df_sorted_per_second)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I59jcOcf70t8",
        "outputId": "77e6ba7a-c8f8-4475-8e65-e6b9c7ab86b7"
      },
      "source": [
        "df_sorted_per_second.show(100, truncate=False)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------------------+--------------+--------------+\n",
            "|id_persona|time (01:00)       |predictedLabel|Num Of Records|\n",
            "+----------+-------------------+--------------+--------------+\n",
            "|0         |2020-05-27T10:16:56|0             |134           |\n",
            "|0         |2020-05-27T10:16:57|0             |200           |\n",
            "|0         |2020-05-27T10:16:58|3             |1             |\n",
            "|0         |2020-05-27T10:16:58|0             |199           |\n",
            "|0         |2020-05-27T10:16:59|0             |200           |\n",
            "|0         |2020-05-27T10:17:00|5             |2             |\n",
            "|0         |2020-05-27T10:17:00|3             |1             |\n",
            "|0         |2020-05-27T10:17:00|0             |197           |\n",
            "|0         |2020-05-27T10:17:01|5             |3             |\n",
            "|0         |2020-05-27T10:17:01|0             |195           |\n",
            "|0         |2020-05-27T10:17:01|3             |2             |\n",
            "|0         |2020-05-27T10:17:02|0             |197           |\n",
            "|0         |2020-05-27T10:17:02|3             |3             |\n",
            "|0         |2020-05-27T10:17:03|3             |7             |\n",
            "|0         |2020-05-27T10:17:03|5             |1             |\n",
            "|0         |2020-05-27T10:17:03|0             |190           |\n",
            "|0         |2020-05-27T10:17:03|4             |2             |\n",
            "|0         |2020-05-27T10:17:04|0             |198           |\n",
            "|0         |2020-05-27T10:17:04|3             |2             |\n",
            "|0         |2020-05-27T10:17:05|0             |200           |\n",
            "|0         |2020-05-27T10:17:06|0             |200           |\n",
            "|0         |2020-05-27T10:17:07|0             |200           |\n",
            "|0         |2020-05-27T10:17:08|0             |200           |\n",
            "|0         |2020-05-27T10:17:09|0             |200           |\n",
            "|0         |2020-05-27T10:17:10|0             |200           |\n",
            "|0         |2020-05-27T10:17:11|0             |200           |\n",
            "|0         |2020-05-27T10:17:12|0             |200           |\n",
            "|0         |2020-05-27T10:17:13|0             |200           |\n",
            "|0         |2020-05-27T10:17:14|0             |200           |\n",
            "|0         |2020-05-27T10:17:15|3             |1             |\n",
            "|0         |2020-05-27T10:17:15|0             |198           |\n",
            "|0         |2020-05-27T10:17:15|5             |1             |\n",
            "|0         |2020-05-27T10:17:16|0             |198           |\n",
            "|0         |2020-05-27T10:17:16|3             |1             |\n",
            "|0         |2020-05-27T10:17:16|4             |1             |\n",
            "|0         |2020-05-27T10:17:17|0             |199           |\n",
            "|0         |2020-05-27T10:17:17|3             |1             |\n",
            "|0         |2020-05-27T10:17:18|0             |200           |\n",
            "|0         |2020-05-27T10:17:19|0             |200           |\n",
            "|0         |2020-05-27T10:17:20|0             |200           |\n",
            "|0         |2020-05-27T10:17:21|0             |200           |\n",
            "|0         |2020-05-27T10:17:22|0             |200           |\n",
            "|0         |2020-05-27T10:17:23|0             |200           |\n",
            "|0         |2020-05-27T10:17:24|0             |200           |\n",
            "|0         |2020-05-27T10:17:25|0             |200           |\n",
            "|0         |2020-05-27T10:17:26|0             |200           |\n",
            "|0         |2020-05-27T10:17:27|0             |200           |\n",
            "|0         |2020-05-27T10:17:28|0             |200           |\n",
            "|0         |2020-05-27T10:17:29|0             |200           |\n",
            "|0         |2020-05-27T10:17:30|0             |200           |\n",
            "|0         |2020-05-27T10:17:31|0             |200           |\n",
            "|0         |2020-05-27T10:17:32|0             |200           |\n",
            "|0         |2020-05-27T10:17:33|0             |200           |\n",
            "|0         |2020-05-27T10:17:34|0             |200           |\n",
            "|0         |2020-05-27T10:17:35|0             |200           |\n",
            "|0         |2020-05-27T10:17:36|0             |200           |\n",
            "|0         |2020-05-27T10:17:37|0             |200           |\n",
            "|0         |2020-05-27T10:17:38|0             |200           |\n",
            "|0         |2020-05-27T10:17:39|0             |199           |\n",
            "|0         |2020-05-27T10:17:39|3             |1             |\n",
            "|0         |2020-05-27T10:17:40|0             |200           |\n",
            "|0         |2020-05-27T10:17:41|0             |199           |\n",
            "|0         |2020-05-27T10:17:41|5             |1             |\n",
            "|0         |2020-05-27T10:17:42|0             |200           |\n",
            "|0         |2020-05-27T10:17:43|0             |200           |\n",
            "|0         |2020-05-27T10:17:44|0             |200           |\n",
            "|0         |2020-05-27T10:17:45|0             |200           |\n",
            "|0         |2020-05-27T10:17:46|3             |1             |\n",
            "|0         |2020-05-27T10:17:46|0             |199           |\n",
            "|0         |2020-05-27T10:17:47|0             |200           |\n",
            "|0         |2020-05-27T10:17:48|0             |200           |\n",
            "|0         |2020-05-27T10:17:49|0             |200           |\n",
            "|0         |2020-05-27T10:17:50|0             |200           |\n",
            "|0         |2020-05-27T10:17:51|0             |200           |\n",
            "|0         |2020-05-27T10:17:52|0             |200           |\n",
            "|0         |2020-05-27T10:17:53|0             |200           |\n",
            "|0         |2020-05-27T10:17:54|0             |200           |\n",
            "|0         |2020-05-27T10:17:55|0             |200           |\n",
            "|0         |2020-05-27T10:17:56|3             |1             |\n",
            "|0         |2020-05-27T10:17:56|0             |199           |\n",
            "|0         |2020-05-27T10:17:57|0             |199           |\n",
            "|0         |2020-05-27T10:17:57|4             |1             |\n",
            "|0         |2020-05-27T10:17:58|3             |18            |\n",
            "|0         |2020-05-27T10:17:58|5             |21            |\n",
            "|0         |2020-05-27T10:17:58|4             |8             |\n",
            "|0         |2020-05-27T10:17:58|0             |122           |\n",
            "|0         |2020-05-27T10:17:59|0             |198           |\n",
            "|0         |2020-05-27T10:17:59|3             |2             |\n",
            "|0         |2020-05-27T10:18:00|0             |199           |\n",
            "|0         |2020-05-27T10:18:00|3             |1             |\n",
            "|0         |2020-05-27T10:18:01|0             |196           |\n",
            "|0         |2020-05-27T10:18:01|3             |4             |\n",
            "|0         |2020-05-27T10:18:02|0             |200           |\n",
            "|0         |2020-05-27T10:18:03|0             |200           |\n",
            "|0         |2020-05-27T10:18:04|0             |181           |\n",
            "|0         |2020-05-27T10:19:18|5             |1             |\n",
            "|0         |2020-05-27T10:19:18|1             |24            |\n",
            "|0         |2020-05-27T10:19:19|1             |200           |\n",
            "|0         |2020-05-27T10:19:20|1             |200           |\n",
            "|0         |2020-05-27T10:19:21|1             |200           |\n",
            "+----------+-------------------+--------------+--------------+\n",
            "only showing top 100 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U444_TTNGtUU"
      },
      "source": [
        "**Il prossimo step e' classificare ciascun secondo in base alla classe che ha il maggior numero di occorrenze nel secondo stesso...**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itIi33k878AE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}